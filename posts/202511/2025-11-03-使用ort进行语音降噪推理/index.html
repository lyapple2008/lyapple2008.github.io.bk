<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>使用ORT进行语音降噪模型推理 | BeYoung</title><meta name=keywords content="音频算法,语音降噪,Onnx Runtime"><meta name=description content="在深度学习语音降噪模型的部署过程中，选择合适的推理引擎至关重要。ONNX Runtime（ORT）作为微软开源的跨平台推理引擎，在性能、兼容性和易用性方面表现出色，已成为许多生产环境的首选。本文将介绍为什么选择ORT，ORT的核心概念和使用流程，以及在使用ORT进行语音降噪推理时需要注意的关键事项，特别是针对时序模型（如GRU/LSTM）的隐状态管理。"><meta name=author content="Marshall Liu"><link rel=canonical href=https://lyapple2008.github.io/posts/202511/2025-11-03-%E4%BD%BF%E7%94%A8ort%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E9%99%8D%E5%99%AA%E6%8E%A8%E7%90%86/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://lyapple2008.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://lyapple2008.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://lyapple2008.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://lyapple2008.github.io/apple-touch-icon.png><link rel=mask-icon href=https://lyapple2008.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://lyapple2008.github.io/posts/202511/2025-11-03-%E4%BD%BF%E7%94%A8ort%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E9%99%8D%E5%99%AA%E6%8E%A8%E7%90%86/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css integrity=sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js integrity=sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script><meta property="og:url" content="https://lyapple2008.github.io/posts/202511/2025-11-03-%E4%BD%BF%E7%94%A8ort%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E9%99%8D%E5%99%AA%E6%8E%A8%E7%90%86/"><meta property="og:site_name" content="BeYoung"><meta property="og:title" content="使用ORT进行语音降噪模型推理"><meta property="og:description" content="在深度学习语音降噪模型的部署过程中，选择合适的推理引擎至关重要。ONNX Runtime（ORT）作为微软开源的跨平台推理引擎，在性能、兼容性和易用性方面表现出色，已成为许多生产环境的首选。本文将介绍为什么选择ORT，ORT的核心概念和使用流程，以及在使用ORT进行语音降噪推理时需要注意的关键事项，特别是针对时序模型（如GRU/LSTM）的隐状态管理。"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-11-03T19:39:53+08:00"><meta property="article:modified_time" content="2025-11-03T19:39:53+08:00"><meta property="article:tag" content="音频算法"><meta property="article:tag" content="语音降噪"><meta property="article:tag" content="Onnx Runtime"><meta property="og:image" content="https://lyapple2008.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://lyapple2008.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="使用ORT进行语音降噪模型推理"><meta name=twitter:description content="在深度学习语音降噪模型的部署过程中，选择合适的推理引擎至关重要。ONNX Runtime（ORT）作为微软开源的跨平台推理引擎，在性能、兼容性和易用性方面表现出色，已成为许多生产环境的首选。本文将介绍为什么选择ORT，ORT的核心概念和使用流程，以及在使用ORT进行语音降噪推理时需要注意的关键事项，特别是针对时序模型（如GRU/LSTM）的隐状态管理。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://lyapple2008.github.io/posts/"},{"@type":"ListItem","position":2,"name":"使用ORT进行语音降噪模型推理","item":"https://lyapple2008.github.io/posts/202511/2025-11-03-%E4%BD%BF%E7%94%A8ort%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E9%99%8D%E5%99%AA%E6%8E%A8%E7%90%86/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"使用ORT进行语音降噪模型推理","name":"使用ORT进行语音降噪模型推理","description":"在深度学习语音降噪模型的部署过程中，选择合适的推理引擎至关重要。ONNX Runtime（ORT）作为微软开源的跨平台推理引擎，在性能、兼容性和易用性方面表现出色，已成为许多生产环境的首选。本文将介绍为什么选择ORT，ORT的核心概念和使用流程，以及在使用ORT进行语音降噪推理时需要注意的关键事项，特别是针对时序模型（如GRU/LSTM）的隐状态管理。\n","keywords":["音频算法","语音降噪","Onnx Runtime"],"articleBody":"在深度学习语音降噪模型的部署过程中，选择合适的推理引擎至关重要。ONNX Runtime（ORT）作为微软开源的跨平台推理引擎，在性能、兼容性和易用性方面表现出色，已成为许多生产环境的首选。本文将介绍为什么选择ORT，ORT的核心概念和使用流程，以及在使用ORT进行语音降噪推理时需要注意的关键事项，特别是针对时序模型（如GRU/LSTM）的隐状态管理。\n一、为什么选择ORT？ 1.1 跨平台支持 ORT提供了广泛的平台支持，包括：\nCPU推理：支持x86、ARM等架构，可在Windows、Linux、macOS、Android、iOS等系统运行 GPU加速：支持CUDA（NVIDIA GPU）、DirectML（Windows）、TensorRT等 专用硬件：支持CoreML（Apple Silicon）、OpenVINO（Intel）、QNN（Qualcomm）等 这种跨平台特性使得同一套代码可以在不同设备上运行，大大降低了部署成本。\n1.2 性能优化 ORT在性能方面做了大量优化：\n图优化：自动进行算子融合、常量折叠、死代码消除等优化 执行提供者（Execution Provider）：针对不同硬件提供专门的优化实现 动态形状支持：支持动态batch size和序列长度，适合实时推理场景 1.3 模型格式标准化 ORT基于ONNX（Open Neural Network Exchange）格式，这是业界标准的模型交换格式：\n框架无关：可以从PyTorch、TensorFlow、Keras等框架导出ONNX模型 版本兼容：ONNX规范持续演进，ORT保持向后兼容 工具生态：丰富的模型转换和优化工具 1.4 易于集成 ORT提供了多种语言绑定：\nC++ API：适合高性能场景和嵌入式设备 Python API：便于快速原型开发和调试 C#、Java、JavaScript：支持多种应用场景 1.5 活跃的社区支持 作为微软开源项目，ORT拥有活跃的社区和持续的更新，bug修复和新功能迭代速度快。\n二、ORT基本概念与推理流程 2.1 核心概念 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ┌───────────────────────────────┐ │ OrtEnv （运行时环境） │ │ └─ 管理全局资源、线程池等 │ └──────────────┬────────────────┘ │ ┌──────────────┴────────────────┐ │ OrtSession （推理会话） │ │ └─ 持有已加载的 ONNX 模型 │ └──────────────┬────────────────┘ │ ┌──────────────┴────────────────────────┐ │ OrtRun（一次推理调用） │ │ ├─ 输入 OrtValue (Tensor 等) │ │ ├─ 输出 OrtValue │ │ └─ 在 Env/Session 的线程池中执行 │ └────────────────────────────────────────┘ OrtEnv（运行时环境） OrtEnv是ORT的全局运行时环境，负责管理线程池、日志等全局资源。通常一个进程只需要创建一个OrtEnv实例：\n1 2 3 4 5 6 7 8 9 10 #include // 创建运行时环境 OrtEnv* env = NULL; OrtStatus* status = OrtCreateEnv(ORT_LOGGING_LEVEL_WARNING, \"ORT\", \u0026env); if (status != NULL) { // 错误处理 const char* msg = OrtGetErrorMessage(status); OrtReleaseStatus(status); } OrtSession（推理会话） OrtSession负责加载ONNX模型并执行推理。创建会话需要先创建会话选项：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include // 1. 创建会话选项 OrtSessionOptions* session_options = NULL; OrtCreateSessionOptions(\u0026session_options); // 2. 创建推理会话 OrtSession* session = NULL; const char* model_path = \"denoise_model.onnx\"; status = OrtCreateSession(env, model_path, session_options, \u0026session); if (status != NULL) { // 错误处理 const char* msg = OrtGetErrorMessage(status); OrtReleaseStatus(status); } // 3. 释放资源（使用完毕后） OrtReleaseSessionOptions(session_options); OrtReleaseSession(session); OrtReleaseEnv(env); Execution Provider (EP) 执行提供者决定了模型在哪个硬件上运行。在C API中，通过OrtSessionOptionsAppendExecutionProvider添加EP：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // CPU执行（默认，无需显式添加） // 直接创建会话即可使用CPU // CUDA执行（需要NVIDIA GPU） OrtSessionOptionsAppendExecutionProvider_CUDA(session_options, 0); // TensorRT执行（需要NVIDIA GPU和TensorRT） OrtTensorRTProviderOptions trt_options = {0}; OrtSessionOptionsAppendExecutionProvider_TensorRT(session_options, \u0026trt_options); // CoreML执行（macOS/iOS） OrtSessionOptionsAppendExecutionProvider_CoreML(session_options, 0); // 创建会话（会按顺序尝试EP，失败则回退到下一个） OrtCreateSession(env, model_path, session_options, \u0026session); Input/Output 模型的输入输出通过OrtValue传递，需要手动创建和管理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // 1. 获取输入输出信息 size_t num_input_nodes; OrtStatus* status = OrtSessionGetInputCount(session, \u0026num_input_nodes); const char* input_name; OrtTypeInfo* input_type_info; OrtSessionGetInputName(session, 0, allocator, \u0026input_name); OrtSessionGetInputTypeInfo(session, 0, \u0026input_type_info); // 2. 准备输入数据 float input_data[] = { /* audio_features数据 */ }; int64_t input_shape[] = {1, 480}; // batch_size, feature_dim size_t input_tensor_size = 480; OrtValue* input_tensor = NULL; OrtMemoryInfo* memory_info; OrtCreateCpuMemoryInfo(OrtArenaAllocator, OrtMemTypeDefault, \u0026memory_info); OrtCreateTensorWithDataAsOrtValue( memory_info, input_data, input_tensor_size * sizeof(float), input_shape, 2, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT, \u0026input_tensor ); // 3. 执行推理 const char* input_names[] = {input_name}; const char* output_names[] = {\"output\"}; // 根据模型实际输出名称 OrtValue* output_tensor = NULL; status = OrtRun(session, NULL, input_names, \u0026input_tensor, 1, output_names, 1, \u0026output_tensor); // 4. 获取输出数据 float* output_data; OrtGetTensorMutableData(output_tensor, (void**)\u0026output_data); // 使用output_data... // 5. 释放资源 OrtReleaseValue(output_tensor); OrtReleaseValue(input_tensor); OrtReleaseMemoryInfo(memory_info); 2.2 性能优化选项 ORT提供了多种性能优化选项，在C API中通过OrtSessionOptions进行配置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 OrtSessionOptions* session_options = NULL; OrtCreateSessionOptions(\u0026session_options); // 图优化级别 // ORT_DISABLE_ALL, ORT_ENABLE_BASIC, ORT_ENABLE_EXTENDED, ORT_ENABLE_ALL OrtSetSessionGraphOptimizationLevel(session_options, ORT_ENABLE_ALL); // 线程数设置 OrtSetIntraOpNumThreads(session_options, 4); // 算子内部并行线程数 OrtSetInterOpNumThreads(session_options, 2); // 算子间并行线程数 // 内存模式 OrtEnableMemPattern(session_options); // 启用内存模式优化 OrtEnableCpuMemArena(session_options); // 启用CPU内存池 // 执行模式 OrtSetSessionExecutionMode(session_options, ORT_SEQUENTIAL); // 顺序执行 // OrtSetSessionExecutionMode(session_options, ORT_PARALLEL); // 并行执行 // 优化配置文件（可选，用于更精细的控制） // OrtSetOptimizedModelFilePath(session_options, \"optimized_model.onnx\"); // 创建会话时应用这些选项 OrtCreateSession(env, model_path, session_options, \u0026session); // 使用完毕后释放 OrtReleaseSessionOptions(session_options); 三、语音降噪推理的特殊注意事项 语音降噪模型通常使用时序建模网络（如GRU、LSTM），这些网络具有隐状态（hidden state），在实时推理时需要特别注意状态管理。\n3.1 为什么ORT不保存隐状态？ ORT（ONNX Runtime）采用**无状态（stateless）**的设计理念，即每次推理调用都是独立的，ORT不会在内部保存任何状态信息。这种设计有以下几个重要原因：\n3.1.1 设计理念：无状态推理 ORT的核心设计原则是每次OrtRun调用都是完全独立的，不依赖之前的调用结果。这种设计带来以下优势：\n线程安全：多个线程可以同时使用同一个OrtSession进行推理，而不会因为共享状态导致竞争条件 可重现性：相同的输入总是产生相同的输出，不受历史状态影响 灵活性：可以灵活控制何时重置状态、何时复用状态，适应不同的应用场景 3.1.2 状态管理的责任归属 在ORT的设计中，状态管理是应用层的责任，而不是推理引擎的责任。这样做的好处是：\n应用层控制：应用可以根据业务需求决定何时重置状态、如何管理多个流的状态 内存管理：应用可以精确控制状态的内存分配和释放时机 多实例支持：同一个模型可以同时处理多个独立的音频流，每个流维护自己的状态 3.1.3 与训练框架的差异 在训练框架（如PyTorch、TensorFlow）中，RNN/LSTM层通常会维护隐状态：\n1 2 3 # PyTorch训练时的行为 lstm = nn.LSTM(input_size, hidden_size) output, (hidden, cell) = lstm(input, (hidden, cell)) # 状态在层内部管理 但在ONNX导出和ORT推理时，隐状态被显式化为模型的输入和输出：\n1 2 3 // ONNX模型结构 // 输入: [audio_features, hidden_state, cell_state] // 显式输入 // 输出: [denoised_features, new_hidden_state, new_cell_state] // 显式输出 这种显式化的设计使得：\n状态在模型外部可见和可控 可以跨框架、跨平台保持一致的行为 便于调试和优化 3.1.4 实际影响 对于语音降噪等时序应用，ORT不保存隐状态意味着：\n必须手动传递状态：每次推理时，需要将上一次的输出状态作为下一次的输入 状态持久化由应用负责：如果需要保存状态（如断点续传），需要应用层实现 多流处理需要独立状态：处理多个音频流时，需要为每个流维护独立的状态变量 这种设计虽然增加了应用层的复杂度，但提供了更大的灵活性和控制力，特别适合生产环境中的复杂场景。\n3.2 实战使用ORT进行Rnnoise降噪推理 RNNoise是一个基于深度学习的实时语音降噪模型，使用了三个GRU层（VAD GRU、Noise GRU、Denoise GRU）进行时序建模。在使用ORT进行推理时，需要特别注意这三个GRU层的隐状态管理。\n3.2.1 转换成ONNX模型时导出GRU隐状态输入输出端口 RNNoise的Keras训练模型通常只接受特征输入，GRU的隐状态在内部管理。但在导出ONNX模型用于ORT推理时，需要将隐状态显式化为模型的输入和输出端口，这样才能在应用层控制状态传递。\n关键步骤：\n重建模型结构：创建一个新的推理模型，为每个GRU层添加initial_state输入和return_state=True输出 复制权重：从训练模型复制所有层的权重到新模型 定义输入输出：新模型有4个输入（features + 3个GRU状态）和5个输出（denoise_output + vad_output + 3个GRU状态） 下图中，左侧为没有导出隐状态的onnx模型可视化图，可以看到gru的隐状态每次都是被重置的；右侧为导出了隐状态的onnx模型可视化图，可以看到gru节点对应了一个gru state输入端口和一个gru state的输出端口。\n以下是完整的转换代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 import keras.backend as K from keras.constraints import Constraint from keras.layers import Input, Dense, GRU, concatenate from keras.models import Model def my_crossentropy(y_true, y_pred): return K.mean(2 * K.abs(y_true - 0.5) * K.binary_crossentropy(y_pred, y_true), axis=-1) def mymask(y_true): return K.minimum(y_true + 1.0, 1.0) def msse(y_true, y_pred): return K.mean(mymask(y_true) * K.square(K.sqrt(y_pred) - K.sqrt(y_true)), axis=-1) def mycost(y_true, y_pred): return K.mean( mymask(y_true) * ( 10 * K.square(K.square(K.sqrt(y_pred) - K.sqrt(y_true))) + K.square(K.sqrt(y_pred) - K.sqrt(y_true)) + 0.01 * K.binary_crossentropy(y_pred, y_true) ), axis=-1, ) def my_accuracy(y_true, y_pred): return K.mean(2 * K.abs(y_true - 0.5) * K.equal(y_true, K.round(y_pred)), axis=-1) class WeightClip(Constraint): # Accept **kwargs to be compatible with Keras deserialization that may pass 'name' etc. def __init__(self, c=2, **kwargs): # kwargs may include 'name' super().__init__() self.c = c def __call__(self, p): return K.clip(p, -self.c, self.c) def get_config(self): return {'name': self.__class__.__name__, 'c': self.c} CUSTOM_OBJECTS = { 'my_crossentropy': my_crossentropy, 'mymask': mymask, 'msse': msse, 'mycost': mycost, 'my_accuracy': my_accuracy, 'WeightClip': WeightClip, } def rebuild_model_with_states(training_model: Model) -\u003e Model: \"\"\" 自动重建模型，添加GRU隐状态输入/输出端口。 如果模型已经有GRU状态端口，直接返回原模型。 \"\"\" # 检查是否已有GRU状态端口 if len(training_model.inputs) == 4 and len(training_model.outputs) == 5: print(\" Model already has GRU state ports, skipping rebuild\") return training_model print(\" Rebuilding model with GRU state inputs/outputs...\") # 新的推理输入（带状态） features_in = Input(shape=(None, 42), name='features') vad_state_in = Input(shape=(24,), name='vad_gru_state') noise_state_in = Input(shape=(48,), name='noise_gru_state') denoise_state_in = Input(shape=(96,), name='denoise_gru_state') # 复制训练模型的层配置并加载权重 # 1) input_dense input_dense_src = training_model.get_layer('input_dense') input_dense = Dense(24, activation='tanh', name='input_dense_export', kernel_constraint=input_dense_src.kernel_constraint, bias_constraint=input_dense_src.bias_constraint) tmp_export = input_dense(features_in) input_dense.set_weights(input_dense_src.get_weights()) # 2) vad_gru (return_sequences+return_state) vad_gru_src = training_model.get_layer('vad_gru') vad_gru_exp = GRU(24, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, return_state=True, name='vad_gru_export', kernel_regularizer=vad_gru_src.kernel_regularizer, recurrent_regularizer=vad_gru_src.recurrent_regularizer, kernel_constraint=vad_gru_src.kernel_constraint, recurrent_constraint=vad_gru_src.recurrent_constraint, bias_constraint=vad_gru_src.bias_constraint) vad_seq, vad_state_out = vad_gru_exp(tmp_export, initial_state=vad_state_in) vad_gru_exp.set_weights(vad_gru_src.get_weights()) # 3) vad_output vad_output_src = training_model.get_layer('vad_output') vad_output_exp_layer = Dense(1, activation='sigmoid', name='vad_output_export', kernel_constraint=vad_output_src.kernel_constraint, bias_constraint=vad_output_src.bias_constraint) vad_output_exp = vad_output_exp_layer(vad_seq) vad_output_exp_layer.set_weights(vad_output_src.get_weights()) # 4) noise_gru 输入：concat([tmp_export, vad_seq, features_in]) noise_in = concatenate([tmp_export, vad_seq, features_in], name='noise_concat_export') noise_gru_src = training_model.get_layer('noise_gru') noise_gru_exp = GRU(48, activation='relu', recurrent_activation='sigmoid', return_sequences=True, return_state=True, name='noise_gru_export', kernel_regularizer=noise_gru_src.kernel_regularizer, recurrent_regularizer=noise_gru_src.recurrent_regularizer, kernel_constraint=noise_gru_src.kernel_constraint, recurrent_constraint=noise_gru_src.recurrent_constraint, bias_constraint=noise_gru_src.bias_constraint) noise_seq, noise_state_out = noise_gru_exp(noise_in, initial_state=noise_state_in) noise_gru_exp.set_weights(noise_gru_src.get_weights()) # 5) denoise_gru 输入：concat([vad_seq, noise_seq, features_in]) denoise_in = concatenate([vad_seq, noise_seq, features_in], name='denoise_concat_export') denoise_gru_src = training_model.get_layer('denoise_gru') denoise_gru_exp = GRU(96, activation='tanh', recurrent_activation='sigmoid', return_sequences=True, return_state=True, name='denoise_gru_export', kernel_regularizer=denoise_gru_src.kernel_regularizer, recurrent_regularizer=denoise_gru_src.recurrent_regularizer, kernel_constraint=denoise_gru_src.kernel_constraint, recurrent_constraint=denoise_gru_src.recurrent_constraint, bias_constraint=denoise_gru_src.bias_constraint) denoise_seq, denoise_state_out = denoise_gru_exp(denoise_in, initial_state=denoise_state_in) denoise_gru_exp.set_weights(denoise_gru_src.get_weights()) # 6) denoise_output denoise_output_src = training_model.get_layer('denoise_output') denoise_output_exp_layer = Dense(22, activation='sigmoid', name='denoise_output_export', kernel_constraint=denoise_output_src.kernel_constraint, bias_constraint=denoise_output_src.bias_constraint) denoise_output_exp = denoise_output_exp_layer(denoise_seq) denoise_output_exp_layer.set_weights(denoise_output_src.get_weights()) export_model = Model( inputs=[features_in, vad_state_in, noise_state_in, denoise_state_in], outputs=[denoise_output_exp, vad_output_exp, vad_state_out, noise_state_out, denoise_state_out], name='rnnoise_export_with_states' ) print(\" ✓ Model rebuilt successfully with GRU state ports\") return export_model def convert(hdf5_path: str, onnx_path: str, opset: int = 13, auto_rebuild: bool = False) -\u003e None: if not os.path.isfile(hdf5_path): raise FileNotFoundError(f\"HDF5 model not found: {hdf5_path}\") print(f\"Loading Keras model from: {hdf5_path}\") # Load with custom objects registered for deserialization model = keras.models.load_model(hdf5_path, custom_objects=CUSTOM_OBJECTS) # Auto-rebuild model with GRU states if needed if auto_rebuild: print(\"\\n=== Auto-Rebuild Mode ===\") print(\" Checking if model needs GRU state ports...\") model = rebuild_model_with_states(model) print(\" Model ready for conversion with GRU state ports\\n\") # Check if the model has GRU state inputs/outputs num_inputs = len(model.inputs) num_outputs = len(model.outputs) print(f\"Model has {num_inputs} input(s) and {num_outputs} output(s)\") # Print input information for i, inp in enumerate(model.inputs): print(f\" Input {i}: {inp.name}, shape: {inp.shape}\") # Print output information for i, out in enumerate(model.outputs): print(f\" Output {i}: {out.name}, shape: {out.shape}\") # Check if this is a model with GRU states (4 inputs and 5 outputs) if num_inputs == 4 and num_outputs == 5: print(\"Detected model with GRU state inputs/outputs\") # Build input signature for model with efficient state management input_specs = [] for inp in model.inputs: inp_name = inp.name.split(':')[0] inp_shape = inp.shape.as_list() # Handle different input shapes if len(inp_shape) == 3: # features: (None, None, 42) spec = tf.TensorSpec([None, None, inp_shape[2]], tf.float32, name=inp_name) elif len(inp_shape) == 2: # GRU states: (None, hidden_size) spec = tf.TensorSpec([None, inp_shape[1]], tf.float32, name=inp_name) else: # Fallback: use dynamic shape spec = tf.TensorSpec([None] * len(inp_shape), tf.float32, name=inp_name) input_specs.append(spec) print(f\"Converting to ONNX (opset {opset}) with GRU state inputs/outputs...\") # Convert with all input signatures tf2onnx.convert.from_keras(model, input_signature=input_specs, output_path=onnx_path, opset=opset) elif num_inputs == 1: print(\"Detected standard model without GRU state ports\") # Use a dynamic input signature (None, None, 42) to preserve time dimension flexibility input_name = model.inputs[0].name.split(':')[0] spec = (tf.TensorSpec([None, None, 42], tf.float32, name=input_name),) print(f\"Converting to ONNX (opset {opset})...\") # Convert directly from the Keras model tf2onnx.convert.from_keras(model, input_signature=spec, output_path=onnx_path, opset=opset) else: # Generic conversion for models with multiple inputs but unknown structure print(f\"Converting to ONNX (opset {opset}) with {num_inputs} inputs...\") input_specs = [] for inp in model.inputs: inp_name = inp.name.split(':')[0] inp_shape = inp.shape.as_list() # Use dynamic shapes for flexibility spec = tf.TensorSpec([None] * len(inp_shape), tf.float32, name=inp_name) input_specs.append(spec) tf2onnx.convert.from_keras(model, input_signature=input_specs, output_path=onnx_path, opset=opset) print(f\"Saved ONNX model to: {onnx_path}\") def main(): parser = argparse.ArgumentParser(description='Convert Keras HDF5 model to ONNX for RNNoise.') parser.add_argument('--input', '-i', required=True, help='Path to Keras HDF5 model file') parser.add_argument('--output', '-o', required=False, help='Path to output ONNX file') parser.add_argument('--opset', type=int, default=13, help='ONNX opset version (default: 13)') parser.add_argument('--auto-rebuild', action='store_true', help='Automatically rebuild model with GRU state ports if missing') args = parser.parse_args() input_path = os.path.abspath(args.input) output_path = args.output if not output_path: base, _ = os.path.splitext(input_path) output_path = base + '.onnx' output_path = os.path.abspath(output_path) os.makedirs(os.path.dirname(output_path), exist_ok=True) convert(input_path, output_path, opset=args.opset, auto_rebuild=args.auto_rebuild) if __name__ == '__main__': main() 3.2.2 推理时对隐状态进行管理 前面导出onnx模型时，已经为每个GRU节点导出了隐状态的输入和输出端口，因此在每一次帧的时候，只需要将上一次推理保存的隐状态信息输入到对应的隐状态输入端口，同时在推理后对GRU节点的隐状态输出端口进行保存，就可以实现流式推理GRU保留历史信息了。\n以下是部分核心函数实现，只需要将其嵌入到原rnnoise降噪代码中就可以实现ort推理了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 // Initialize ONNX model int initialize_onnx_model(RNNoiseContext* ctx, const char* model_path) { // Get ONNX Runtime API const OrtApiBase* api_base = OrtGetApiBase(); if (!api_base) { fprintf(stderr, \"Error getting ONNX Runtime API base\\n\"); return -1; } ctx-\u003eapi = api_base-\u003eGetApi(ORT_API_VERSION); if (!ctx-\u003eapi) { fprintf(stderr, \"Error getting ONNX Runtime API\\n\"); return -1; } // Initialize ONNX Runtime environment OrtStatus* status = ctx-\u003eapi-\u003eCreateEnv(ORT_LOGGING_LEVEL_WARNING, \"RNNoiseONNX\", \u0026ctx-\u003eenv); if (status != NULL) { fprintf(stderr, \"Error creating ONNX Runtime environment\\n\"); return -1; } // Create session options status = ctx-\u003eapi-\u003eCreateSessionOptions(\u0026ctx-\u003esession_options); if (status != NULL) { fprintf(stderr, \"Error creating session options\\n\"); return -1; } // Set session options status = ctx-\u003eapi-\u003eSetIntraOpNumThreads(ctx-\u003esession_options, 1); if (status != NULL) { fprintf(stderr, \"Error setting intra-op threads\\n\"); return -1; } status = ctx-\u003eapi-\u003eSetSessionGraphOptimizationLevel(ctx-\u003esession_options, ORT_ENABLE_EXTENDED); if (status != NULL) { fprintf(stderr, \"Error setting optimization level\\n\"); return -1; } // Create session status = ctx-\u003eapi-\u003eCreateSession(ctx-\u003eenv, model_path, ctx-\u003esession_options, \u0026ctx-\u003esession); if (status != NULL) { fprintf(stderr, \"Error creating ONNX session\\n\"); return -1; } // Get allocator status = ctx-\u003eapi-\u003eGetAllocatorWithDefaultOptions(\u0026ctx-\u003eallocator); if (status != NULL) { fprintf(stderr, \"Error getting allocator\\n\"); return -1; } // Get input/output names size_t num_input_nodes, num_output_nodes; status = ctx-\u003eapi-\u003eSessionGetInputCount(ctx-\u003esession, \u0026num_input_nodes); if (status != NULL) { fprintf(stderr, \"Error getting input count\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetOutputCount(ctx-\u003esession, \u0026num_output_nodes); if (status != NULL) { fprintf(stderr, \"Error getting output count\\n\"); return -1; } printf(\"ONNX Model Info:\\n\"); printf(\" Input nodes: %zu\\n\", num_input_nodes); printf(\" Output nodes: %zu\\n\", num_output_nodes); // Detect model type: 4 inputs + 5 outputs = model with GRU states ctx-\u003ehas_gru_states = (num_input_nodes == 4 \u0026\u0026 num_output_nodes == 5); if (ctx-\u003ehas_gru_states) { printf(\" Model type: WITH GRU state inputs/outputs\\n\"); // Get all input names status = ctx-\u003eapi-\u003eSessionGetInputName(ctx-\u003esession, 0, ctx-\u003eallocator, \u0026ctx-\u003einput_name); if (status != NULL) { fprintf(stderr, \"Error getting features input name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetInputName(ctx-\u003esession, 1, ctx-\u003eallocator, \u0026ctx-\u003einput_name_vad_state); if (status != NULL) { fprintf(stderr, \"Error getting VAD state input name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetInputName(ctx-\u003esession, 2, ctx-\u003eallocator, \u0026ctx-\u003einput_name_noise_state); if (status != NULL) { fprintf(stderr, \"Error getting noise state input name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetInputName(ctx-\u003esession, 3, ctx-\u003eallocator, \u0026ctx-\u003einput_name_denoise_state); if (status != NULL) { fprintf(stderr, \"Error getting denoise state input name\\n\"); return -1; } // Get all output names status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 0, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_denoise); if (status != NULL) { fprintf(stderr, \"Error getting denoise output name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 1, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_vad); if (status != NULL) { fprintf(stderr, \"Error getting VAD output name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 2, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_vad_state); if (status != NULL) { fprintf(stderr, \"Error getting VAD state output name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 3, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_noise_state); if (status != NULL) { fprintf(stderr, \"Error getting noise state output name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 4, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_denoise_state); if (status != NULL) { fprintf(stderr, \"Error getting denoise state output name\\n\"); return -1; } printf(\" Inputs:\\n\"); printf(\" [0] %s (features)\\n\", ctx-\u003einput_name); printf(\" [1] %s (VAD GRU state)\\n\", ctx-\u003einput_name_vad_state); printf(\" [2] %s (noise GRU state)\\n\", ctx-\u003einput_name_noise_state); printf(\" [3] %s (denoise GRU state)\\n\", ctx-\u003einput_name_denoise_state); printf(\" Outputs:\\n\"); printf(\" [0] %s (denoise)\\n\", ctx-\u003eoutput_name_denoise); printf(\" [1] %s (VAD)\\n\", ctx-\u003eoutput_name_vad); printf(\" [2] %s (VAD GRU state)\\n\", ctx-\u003eoutput_name_vad_state); printf(\" [3] %s (noise GRU state)\\n\", ctx-\u003eoutput_name_noise_state); printf(\" [4] %s (denoise GRU state)\\n\", ctx-\u003eoutput_name_denoise_state); } else { printf(\" Model type: Standard (without GRU state ports)\\n\"); // Get input name (standard model) status = ctx-\u003eapi-\u003eSessionGetInputName(ctx-\u003esession, 0, ctx-\u003eallocator, \u0026ctx-\u003einput_name); if (status != NULL) { fprintf(stderr, \"Error getting input name\\n\"); return -1; } // Get output names (standard model) status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 0, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_denoise); if (status != NULL) { fprintf(stderr, \"Error getting denoise output name\\n\"); return -1; } status = ctx-\u003eapi-\u003eSessionGetOutputName(ctx-\u003esession, 1, ctx-\u003eallocator, \u0026ctx-\u003eoutput_name_vad); if (status != NULL) { fprintf(stderr, \"Error getting VAD output name\\n\"); return -1; } printf(\" Input: %s\\n\", ctx-\u003einput_name); printf(\" Output denoise: %s\\n\", ctx-\u003eoutput_name_denoise); printf(\" Output VAD: %s\\n\", ctx-\u003eoutput_name_vad); } // Allocate buffers ctx-\u003einput_buffer = (float*)malloc(FRAME_SIZE * sizeof(float)); ctx-\u003eoutput_buffer = (float*)malloc(FRAME_SIZE * sizeof(float)); if (!ctx-\u003einput_buffer || !ctx-\u003eoutput_buffer) { fprintf(stderr, \"Error: Memory allocation failed\\n\"); return -1; } // Initialize RNNoise state for feature extraction ctx-\u003edenoise_state = rnnoise_create(NULL); if (!ctx-\u003edenoise_state) { fprintf(stderr, \"Error: Failed to create RNNoise state\\n\"); return -1; } rnnoise_init(ctx-\u003edenoise_state, NULL); // Initialize biquad filter memory ctx-\u003emem_hp_x[0] = 0.0f; ctx-\u003emem_hp_x[1] = 0.0f; // Initialize processing buffers memset(ctx-\u003eX, 0, sizeof(ctx-\u003eX)); memset(ctx-\u003eP, 0, sizeof(ctx-\u003eP)); memset(ctx-\u003eEx, 0, sizeof(ctx-\u003eEx)); memset(ctx-\u003eEp, 0, sizeof(ctx-\u003eEp)); memset(ctx-\u003eExp, 0, sizeof(ctx-\u003eExp)); memset(ctx-\u003elastg, 0, sizeof(ctx-\u003elastg)); memset(ctx-\u003esynthesis_mem, 0, sizeof(ctx-\u003esynthesis_mem)); // Initialize frame count ctx-\u003eframe_count = 0; // Initialize GRU states if model supports it initialize_gru_states(ctx); printf(\"ONNX model loaded successfully: %s\\n\", model_path); return 0; } // Initialize GRU states void initialize_gru_states(RNNoiseContext* ctx) { memset(ctx-\u003evad_gru_state, 0, sizeof(ctx-\u003evad_gru_state)); memset(ctx-\u003enoise_gru_state, 0, sizeof(ctx-\u003enoise_gru_state)); memset(ctx-\u003edenoise_gru_state, 0, sizeof(ctx-\u003edenoise_gru_state)); ctx-\u003egru_states_initialized = 0; } // ONNX inference with external state management int onnx_inference_with_states(RNNoiseContext* ctx, const float* features, float* gains, float* vad) { // Prepare separate input tensors for features and GRU states float features_data[42]; float vad_state_data[24]; float noise_state_data[48]; float denoise_state_data[96]; // Copy features memcpy(features_data, features, 42 * sizeof(float)); // Copy GRU states (use saved states for next frame) memcpy(vad_state_data, ctx-\u003evad_gru_state, 24 * sizeof(float)); memcpy(noise_state_data, ctx-\u003enoise_gru_state, 48 * sizeof(float)); memcpy(denoise_state_data, ctx-\u003edenoise_gru_state, 96 * sizeof(float)); // Create input tensors const int64_t features_shape[] = {1, 1, 42}; const int64_t vad_state_shape[] = {1, 24}; const int64_t noise_state_shape[] = {1, 48}; const int64_t denoise_state_shape[] = {1, 96}; OrtMemoryInfo* memory_info; OrtStatus* status = ctx-\u003eapi-\u003eCreateCpuMemoryInfo(OrtArenaAllocator, OrtMemTypeDefault, \u0026memory_info); if (status != NULL) { fprintf(stderr, \"Error creating memory info\\n\"); return -1; } // Create input tensors OrtValue* features_tensor = NULL; OrtValue* vad_state_tensor = NULL; OrtValue* noise_state_tensor = NULL; OrtValue* denoise_state_tensor = NULL; status = ctx-\u003eapi-\u003eCreateTensorWithDataAsOrtValue( memory_info, features_data, 42 * sizeof(float), features_shape, 3, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT, \u0026features_tensor); if (status != NULL) { fprintf(stderr, \"Error creating features tensor\\n\"); ctx-\u003eapi-\u003eReleaseMemoryInfo(memory_info); return -1; } status = ctx-\u003eapi-\u003eCreateTensorWithDataAsOrtValue( memory_info, vad_state_data, 24 * sizeof(float), vad_state_shape, 2, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT, \u0026vad_state_tensor); if (status != NULL) { fprintf(stderr, \"Error creating VAD state tensor\\n\"); ctx-\u003eapi-\u003eReleaseValue(features_tensor); ctx-\u003eapi-\u003eReleaseMemoryInfo(memory_info); return -1; } status = ctx-\u003eapi-\u003eCreateTensorWithDataAsOrtValue( memory_info, noise_state_data, 48 * sizeof(float), noise_state_shape, 2, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT, \u0026noise_state_tensor); if (status != NULL) { fprintf(stderr, \"Error creating noise state tensor\\n\"); ctx-\u003eapi-\u003eReleaseValue(features_tensor); ctx-\u003eapi-\u003eReleaseValue(vad_state_tensor); ctx-\u003eapi-\u003eReleaseMemoryInfo(memory_info); return -1; } status = ctx-\u003eapi-\u003eCreateTensorWithDataAsOrtValue( memory_info, denoise_state_data, 96 * sizeof(float), denoise_state_shape, 2, ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT, \u0026denoise_state_tensor); if (status != NULL) { fprintf(stderr, \"Error creating denoise state tensor\\n\"); ctx-\u003eapi-\u003eReleaseValue(features_tensor); ctx-\u003eapi-\u003eReleaseValue(vad_state_tensor); ctx-\u003eapi-\u003eReleaseValue(noise_state_tensor); ctx-\u003eapi-\u003eReleaseMemoryInfo(memory_info); return -1; } // Prepare input names and tensors const char* input_names[] = {ctx-\u003einput_name, ctx-\u003einput_name_vad_state, ctx-\u003einput_name_noise_state, ctx-\u003einput_name_denoise_state}; OrtValue* input_tensors[] = {features_tensor, vad_state_tensor, noise_state_tensor, denoise_state_tensor}; // Prepare output names const char* output_names[] = {ctx-\u003eoutput_name_denoise, ctx-\u003eoutput_name_vad, ctx-\u003eoutput_name_vad_state, ctx-\u003eoutput_name_noise_state, ctx-\u003eoutput_name_denoise_state}; OrtValue* output_tensors[5] = {NULL, NULL, NULL, NULL, NULL}; // Run inference status = ctx-\u003eapi-\u003eRun(ctx-\u003esession, NULL, input_names, (const OrtValue* const*)input_tensors, 4, output_names, 5, output_tensors); if (status != NULL) { fprintf(stderr, \"Error running inference\\n\"); ctx-\u003eapi-\u003eReleaseValue(features_tensor); ctx-\u003eapi-\u003eReleaseValue(vad_state_tensor); ctx-\u003eapi-\u003eReleaseValue(noise_state_tensor); ctx-\u003eapi-\u003eReleaseValue(denoise_state_tensor); ctx-\u003eapi-\u003eReleaseMemoryInfo(memory_info); return -1; } // Get output data float* denoise_output = NULL; float* vad_output = NULL; float* updated_vad_state = NULL; float* updated_noise_state = NULL; float* updated_denoise_state = NULL; status = ctx-\u003eapi-\u003eGetTensorMutableData(output_tensors[0], (void**)\u0026denoise_output); if (status != NULL) { fprintf(stderr, \"Error getting denoise output data\\n\"); goto cleanup; } status = ctx-\u003eapi-\u003eGetTensorMutableData(output_tensors[1], (void**)\u0026vad_output); if (status != NULL) { fprintf(stderr, \"Error getting VAD output data\\n\"); goto cleanup; } status = ctx-\u003eapi-\u003eGetTensorMutableData(output_tensors[2], (void**)\u0026updated_vad_state); if (status != NULL) { fprintf(stderr, \"Error getting updated VAD state data\\n\"); goto cleanup; } status = ctx-\u003eapi-\u003eGetTensorMutableData(output_tensors[3], (void**)\u0026updated_noise_state); if (status != NULL) { fprintf(stderr, \"Error getting updated noise state data\\n\"); goto cleanup; } status = ctx-\u003eapi-\u003eGetTensorMutableData(output_tensors[4], (void**)\u0026updated_denoise_state); if (status != NULL) { fprintf(stderr, \"Error getting updated denoise state data\\n\"); goto cleanup; } // Store results memcpy(gains, denoise_output, NB_BANDS * sizeof(float)); *vad = vad_output[0]; // Update GRU states with the outputs from the model (for next frame) memcpy(ctx-\u003evad_gru_state, updated_vad_state, 24 * sizeof(float)); memcpy(ctx-\u003enoise_gru_state, updated_noise_state, 48 * sizeof(float)); memcpy(ctx-\u003edenoise_gru_state, updated_denoise_state, 96 * sizeof(float)); ctx-\u003egru_states_initialized = 1; cleanup: // Cleanup ctx-\u003eapi-\u003eReleaseValue(features_tensor); ctx-\u003eapi-\u003eReleaseValue(vad_state_tensor); ctx-\u003eapi-\u003eReleaseValue(noise_state_tensor); ctx-\u003eapi-\u003eReleaseValue(denoise_state_tensor); for (int i = 0; i \u003c 5; i++) { if (output_tensors[i]) { ctx-\u003eapi-\u003eReleaseValue(output_tensors[i]); } } ctx-\u003eapi-\u003eReleaseMemoryInfo(memory_info); return 0; } 3.3 推理性能对比 可以看到在不需要自己手搓各个算子的C实现，借助ORT就可以实现接近5倍的性能提升，这投入回报比可是不要太高了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 === Overall Inference Time Statistics === Total frames processed: 2048 Frames with inference: 2047 ONNX Inference: Total time: 73.568 ms Average per frame: 0.036 ms C Inference: Total time: 349.820 ms Average per frame: 0.171 ms Comparison: ONNX / C ratio: 0.21x Speedup: 4.76x (ONNX faster) ========================================== 四、总结 ORT作为跨平台的推理引擎，在语音降噪模型部署中具有显著优势。正确使用ORT需要：\n理解基本概念：掌握InferenceSession、Execution Provider等核心概念 遵循推理流程：按照标准的加载、准备、执行、获取结果流程 管理隐状态：对于时序模型，必须正确管理隐状态的传递和更新 性能优化：根据场景选择合适的优化选项和执行提供者 对于实时语音降噪场景，隐状态管理是关键，需要仔细设计状态传递逻辑，确保模型能够正确利用历史信息。\n通过合理使用ORT，可以充分发挥深度学习语音降噪模型的性能，实现高效、稳定的实时推理。\n另外，ORT还有很多高级特性，大家可以自己摸索尝试下。\n","wordCount":"6916","inLanguage":"zh","image":"https://lyapple2008.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-11-03T19:39:53+08:00","dateModified":"2025-11-03T19:39:53+08:00","author":{"@type":"Person","name":"Marshall Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://lyapple2008.github.io/posts/202511/2025-11-03-%E4%BD%BF%E7%94%A8ort%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E9%99%8D%E5%99%AA%E6%8E%A8%E7%90%86/"},"publisher":{"@type":"Organization","name":"BeYoung","logo":{"@type":"ImageObject","url":"https://lyapple2008.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://lyapple2008.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://lyapple2008.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://lyapple2008.github.io/search/ title=搜索><span>搜索</span></a></li><li><a href=https://lyapple2008.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://lyapple2008.github.io/about_me/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://lyapple2008.github.io/>主页</a>&nbsp;»&nbsp;<a href=https://lyapple2008.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">使用ORT进行语音降噪模型推理</h1><div class=post-meta><span title='2025-11-03 19:39:53 +0800 CST'>十一月 3, 2025</span>&nbsp;·&nbsp;14 分钟&nbsp;·&nbsp;6916 字&nbsp;·&nbsp;Marshall Liu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#一为什么选择ort>一、为什么选择ORT？</a><ul><li><a href=#11-跨平台支持>1.1 跨平台支持</a></li><li><a href=#12-性能优化>1.2 性能优化</a></li><li><a href=#13-模型格式标准化>1.3 模型格式标准化</a></li><li><a href=#14-易于集成>1.4 易于集成</a></li><li><a href=#15-活跃的社区支持>1.5 活跃的社区支持</a></li></ul></li><li><a href=#二ort基本概念与推理流程>二、ORT基本概念与推理流程</a><ul><li><a href=#21-核心概念>2.1 核心概念</a></li><li><a href=#22-性能优化选项>2.2 性能优化选项</a></li></ul></li><li><a href=#三语音降噪推理的特殊注意事项>三、语音降噪推理的特殊注意事项</a><ul><li><a href=#31-为什么ort不保存隐状态>3.1 为什么ORT不保存隐状态？</a></li><li><a href=#32-实战使用ort进行rnnoise降噪推理>3.2 实战使用ORT进行Rnnoise降噪推理</a></li><li><a href=#33-推理性能对比>3.3 推理性能对比</a></li></ul></li><li><a href=#四总结>四、总结</a></li></ul></nav></div></details></div><div class=post-content><p>在深度学习语音降噪模型的部署过程中，选择合适的推理引擎至关重要。ONNX Runtime（ORT）作为微软开源的跨平台推理引擎，在性能、兼容性和易用性方面表现出色，已成为许多生产环境的首选。本文将介绍为什么选择ORT，ORT的核心概念和使用流程，以及在使用ORT进行语音降噪推理时需要注意的关键事项，特别是针对时序模型（如GRU/LSTM）的隐状态管理。</p><h2 id=一为什么选择ort>一、为什么选择ORT？<a hidden class=anchor aria-hidden=true href=#一为什么选择ort>#</a></h2><h3 id=11-跨平台支持>1.1 跨平台支持<a hidden class=anchor aria-hidden=true href=#11-跨平台支持>#</a></h3><p>ORT提供了广泛的平台支持，包括：</p><ul><li><strong>CPU推理</strong>：支持x86、ARM等架构，可在Windows、Linux、macOS、Android、iOS等系统运行</li><li><strong>GPU加速</strong>：支持CUDA（NVIDIA GPU）、DirectML（Windows）、TensorRT等</li><li><strong>专用硬件</strong>：支持CoreML（Apple Silicon）、OpenVINO（Intel）、QNN（Qualcomm）等</li></ul><p>这种跨平台特性使得同一套代码可以在不同设备上运行，大大降低了部署成本。</p><h3 id=12-性能优化>1.2 性能优化<a hidden class=anchor aria-hidden=true href=#12-性能优化>#</a></h3><p>ORT在性能方面做了大量优化：</p><ul><li><strong>图优化</strong>：自动进行算子融合、常量折叠、死代码消除等优化</li><li><strong>执行提供者（Execution Provider）</strong>：针对不同硬件提供专门的优化实现</li><li><strong>动态形状支持</strong>：支持动态batch size和序列长度，适合实时推理场景</li></ul><h3 id=13-模型格式标准化>1.3 模型格式标准化<a hidden class=anchor aria-hidden=true href=#13-模型格式标准化>#</a></h3><p>ORT基于ONNX（Open Neural Network Exchange）格式，这是业界标准的模型交换格式：</p><ul><li><strong>框架无关</strong>：可以从PyTorch、TensorFlow、Keras等框架导出ONNX模型</li><li><strong>版本兼容</strong>：ONNX规范持续演进，ORT保持向后兼容</li><li><strong>工具生态</strong>：丰富的模型转换和优化工具</li></ul><h3 id=14-易于集成>1.4 易于集成<a hidden class=anchor aria-hidden=true href=#14-易于集成>#</a></h3><p>ORT提供了多种语言绑定：</p><ul><li><strong>C++ API</strong>：适合高性能场景和嵌入式设备</li><li><strong>Python API</strong>：便于快速原型开发和调试</li><li><strong>C#、Java、JavaScript</strong>：支持多种应用场景</li></ul><h3 id=15-活跃的社区支持>1.5 活跃的社区支持<a hidden class=anchor aria-hidden=true href=#15-活跃的社区支持>#</a></h3><p>作为微软开源项目，ORT拥有活跃的社区和持续的更新，bug修复和新功能迭代速度快。</p><h2 id=二ort基本概念与推理流程>二、ORT基本概念与推理流程<a hidden class=anchor aria-hidden=true href=#二ort基本概念与推理流程>#</a></h2><h3 id=21-核心概念>2.1 核心概念<a hidden class=anchor aria-hidden=true href=#21-核心概念>#</a></h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>   ┌───────────────────────────────┐
</span></span><span class=line><span class=cl>   │ OrtEnv （运行时环境）         │
</span></span><span class=line><span class=cl>   │ └─ 管理全局资源、线程池等     │
</span></span><span class=line><span class=cl>   └──────────────┬────────────────┘
</span></span><span class=line><span class=cl>                  │
</span></span><span class=line><span class=cl>   ┌──────────────┴────────────────┐
</span></span><span class=line><span class=cl>   │ OrtSession （推理会话）        │
</span></span><span class=line><span class=cl>   │ └─ 持有已加载的 ONNX 模型      │
</span></span><span class=line><span class=cl>   └──────────────┬────────────────┘
</span></span><span class=line><span class=cl>                  │
</span></span><span class=line><span class=cl>   ┌──────────────┴────────────────────────┐
</span></span><span class=line><span class=cl>   │ OrtRun（一次推理调用）                │
</span></span><span class=line><span class=cl>   │ ├─ 输入 OrtValue (Tensor 等)           │
</span></span><span class=line><span class=cl>   │ ├─ 输出 OrtValue                      │
</span></span><span class=line><span class=cl>   │ └─ 在 Env/Session 的线程池中执行      │
</span></span><span class=line><span class=cl>   └────────────────────────────────────────┘</span></span></code></pre></td></tr></table></div></div><h4 id=ortenv运行时环境>OrtEnv（运行时环境）<a hidden class=anchor aria-hidden=true href=#ortenv运行时环境>#</a></h4><p><code>OrtEnv</code>是ORT的全局运行时环境，负责管理线程池、日志等全局资源。通常一个进程只需要创建一个<code>OrtEnv</code>实例：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;onnxruntime_c_api.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=c1>// 创建运行时环境
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>OrtEnv</span><span class=o>*</span> <span class=n>env</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>OrtStatus</span><span class=o>*</span> <span class=n>status</span> <span class=o>=</span> <span class=nf>OrtCreateEnv</span><span class=p>(</span><span class=n>ORT_LOGGING_LEVEL_WARNING</span><span class=p>,</span> <span class=s>&#34;ORT&#34;</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>env</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// 错误处理
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>msg</span> <span class=o>=</span> <span class=nf>OrtGetErrorMessage</span><span class=p>(</span><span class=n>status</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>OrtReleaseStatus</span><span class=p>(</span><span class=n>status</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><h4 id=ortsession推理会话>OrtSession（推理会话）<a hidden class=anchor aria-hidden=true href=#ortsession推理会话>#</a></h4><p><code>OrtSession</code>负责加载ONNX模型并执行推理。创建会话需要先创建会话选项：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=cp>#include</span> <span class=cpf>&lt;onnxruntime_c_api.h&gt;</span><span class=cp>
</span></span></span><span class=line><span class=cl><span class=cp></span>
</span></span><span class=line><span class=cl><span class=c1>// 1. 创建会话选项
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>OrtSessionOptions</span><span class=o>*</span> <span class=n>session_options</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>OrtCreateSessionOptions</span><span class=p>(</span><span class=o>&amp;</span><span class=n>session_options</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 2. 创建推理会话
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>OrtSession</span><span class=o>*</span> <span class=n>session</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>model_path</span> <span class=o>=</span> <span class=s>&#34;denoise_model.onnx&#34;</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>status</span> <span class=o>=</span> <span class=nf>OrtCreateSession</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>model_path</span><span class=p>,</span> <span class=n>session_options</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>session</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// 错误处理
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>msg</span> <span class=o>=</span> <span class=nf>OrtGetErrorMessage</span><span class=p>(</span><span class=n>status</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>OrtReleaseStatus</span><span class=p>(</span><span class=n>status</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 3. 释放资源（使用完毕后）
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtReleaseSessionOptions</span><span class=p>(</span><span class=n>session_options</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>OrtReleaseSession</span><span class=p>(</span><span class=n>session</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>OrtReleaseEnv</span><span class=p>(</span><span class=n>env</span><span class=p>);</span></span></span></code></pre></td></tr></table></div></div><h4 id=execution-provider-ep>Execution Provider (EP)<a hidden class=anchor aria-hidden=true href=#execution-provider-ep>#</a></h4><p>执行提供者决定了模型在哪个硬件上运行。在C API中，通过<code>OrtSessionOptionsAppendExecutionProvider</code>添加EP：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>// CPU执行（默认，无需显式添加）
</span></span></span><span class=line><span class=cl><span class=c1>// 直接创建会话即可使用CPU
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// CUDA执行（需要NVIDIA GPU）
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtSessionOptionsAppendExecutionProvider_CUDA</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// TensorRT执行（需要NVIDIA GPU和TensorRT）
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>OrtTensorRTProviderOptions</span> <span class=n>trt_options</span> <span class=o>=</span> <span class=p>{</span><span class=mi>0</span><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=nf>OrtSessionOptionsAppendExecutionProvider_TensorRT</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>trt_options</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// CoreML执行（macOS/iOS）
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtSessionOptionsAppendExecutionProvider_CoreML</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=mi>0</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 创建会话（会按顺序尝试EP，失败则回退到下一个）
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtCreateSession</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>model_path</span><span class=p>,</span> <span class=n>session_options</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>session</span><span class=p>);</span></span></span></code></pre></td></tr></table></div></div><h4 id=inputoutput>Input/Output<a hidden class=anchor aria-hidden=true href=#inputoutput>#</a></h4><p>模型的输入输出通过<code>OrtValue</code>传递，需要手动创建和管理：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>// 1. 获取输入输出信息
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>size_t</span> <span class=n>num_input_nodes</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>OrtStatus</span><span class=o>*</span> <span class=n>status</span> <span class=o>=</span> <span class=nf>OrtSessionGetInputCount</span><span class=p>(</span><span class=n>session</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>num_input_nodes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>input_name</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>OrtTypeInfo</span><span class=o>*</span> <span class=n>input_type_info</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>OrtSessionGetInputName</span><span class=p>(</span><span class=n>session</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>input_name</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>OrtSessionGetInputTypeInfo</span><span class=p>(</span><span class=n>session</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>input_type_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 2. 准备输入数据
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>float</span> <span class=n>input_data</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span> <span class=cm>/* audio_features数据 */</span> <span class=p>};</span>
</span></span><span class=line><span class=cl><span class=kt>int64_t</span> <span class=n>input_shape</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>1</span><span class=p>,</span> <span class=mi>480</span><span class=p>};</span>  <span class=c1>// batch_size, feature_dim
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>size_t</span> <span class=n>input_tensor_size</span> <span class=o>=</span> <span class=mi>480</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>OrtValue</span><span class=o>*</span> <span class=n>input_tensor</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=n>OrtMemoryInfo</span><span class=o>*</span> <span class=n>memory_info</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>OrtCreateCpuMemoryInfo</span><span class=p>(</span><span class=n>OrtArenaAllocator</span><span class=p>,</span> <span class=n>OrtMemTypeDefault</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>OrtCreateTensorWithDataAsOrtValue</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>memory_info</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>input_data</span><span class=p>,</span> <span class=n>input_tensor_size</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>input_shape</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=o>&amp;</span><span class=n>input_tensor</span>
</span></span><span class=line><span class=cl><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 3. 执行推理
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>input_names</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=n>input_name</span><span class=p>};</span>
</span></span><span class=line><span class=cl><span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>output_names</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=s>&#34;output&#34;</span><span class=p>};</span>  <span class=c1>// 根据模型实际输出名称
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>OrtValue</span><span class=o>*</span> <span class=n>output_tensor</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>status</span> <span class=o>=</span> <span class=nf>OrtRun</span><span class=p>(</span><span class=n>session</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>input_names</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>input_tensor</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>output_names</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>output_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 4. 获取输出数据
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>float</span><span class=o>*</span> <span class=n>output_data</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>OrtGetTensorMutableData</span><span class=p>(</span><span class=n>output_tensor</span><span class=p>,</span> <span class=p>(</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>output_data</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=c1>// 使用output_data...
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// 5. 释放资源
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtReleaseValue</span><span class=p>(</span><span class=n>output_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>OrtReleaseValue</span><span class=p>(</span><span class=n>input_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=nf>OrtReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span></span></span></code></pre></td></tr></table></div></div><h3 id=22-性能优化选项>2.2 性能优化选项<a hidden class=anchor aria-hidden=true href=#22-性能优化选项>#</a></h3><p>ORT提供了多种性能优化选项，在C API中通过<code>OrtSessionOptions</code>进行配置：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=n>OrtSessionOptions</span><span class=o>*</span> <span class=n>session_options</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=nf>OrtCreateSessionOptions</span><span class=p>(</span><span class=o>&amp;</span><span class=n>session_options</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 图优化级别
</span></span></span><span class=line><span class=cl><span class=c1>// ORT_DISABLE_ALL, ORT_ENABLE_BASIC, ORT_ENABLE_EXTENDED, ORT_ENABLE_ALL
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtSetSessionGraphOptimizationLevel</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=n>ORT_ENABLE_ALL</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 线程数设置
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtSetIntraOpNumThreads</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=mi>4</span><span class=p>);</span>  <span class=c1>// 算子内部并行线程数
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtSetInterOpNumThreads</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=mi>2</span><span class=p>);</span> <span class=c1>// 算子间并行线程数
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// 内存模式
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtEnableMemPattern</span><span class=p>(</span><span class=n>session_options</span><span class=p>);</span>  <span class=c1>// 启用内存模式优化
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtEnableCpuMemArena</span><span class=p>(</span><span class=n>session_options</span><span class=p>);</span> <span class=c1>// 启用CPU内存池
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// 执行模式
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtSetSessionExecutionMode</span><span class=p>(</span><span class=n>session_options</span><span class=p>,</span> <span class=n>ORT_SEQUENTIAL</span><span class=p>);</span>  <span class=c1>// 顺序执行
</span></span></span><span class=line><span class=cl><span class=c1>// OrtSetSessionExecutionMode(session_options, ORT_PARALLEL);  // 并行执行
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// 优化配置文件（可选，用于更精细的控制）
</span></span></span><span class=line><span class=cl><span class=c1>// OrtSetOptimizedModelFilePath(session_options, &#34;optimized_model.onnx&#34;);
</span></span></span><span class=line><span class=cl><span class=c1></span>
</span></span><span class=line><span class=cl><span class=c1>// 创建会话时应用这些选项
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtCreateSession</span><span class=p>(</span><span class=n>env</span><span class=p>,</span> <span class=n>model_path</span><span class=p>,</span> <span class=n>session_options</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>session</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// 使用完毕后释放
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=nf>OrtReleaseSessionOptions</span><span class=p>(</span><span class=n>session_options</span><span class=p>);</span></span></span></code></pre></td></tr></table></div></div><h2 id=三语音降噪推理的特殊注意事项>三、语音降噪推理的特殊注意事项<a hidden class=anchor aria-hidden=true href=#三语音降噪推理的特殊注意事项>#</a></h2><p>语音降噪模型通常使用时序建模网络（如GRU、LSTM），这些网络具有隐状态（hidden state），在实时推理时需要特别注意状态管理。</p><h3 id=31-为什么ort不保存隐状态>3.1 为什么ORT不保存隐状态？<a hidden class=anchor aria-hidden=true href=#31-为什么ort不保存隐状态>#</a></h3><p>ORT（ONNX Runtime）采用**无状态（stateless）**的设计理念，即每次推理调用都是独立的，ORT不会在内部保存任何状态信息。这种设计有以下几个重要原因：</p><h4 id=311-设计理念无状态推理>3.1.1 设计理念：无状态推理<a hidden class=anchor aria-hidden=true href=#311-设计理念无状态推理>#</a></h4><p>ORT的核心设计原则是每次<code>OrtRun</code>调用都是完全独立的，不依赖之前的调用结果。这种设计带来以下优势：</p><ol><li><strong>线程安全</strong>：多个线程可以同时使用同一个<code>OrtSession</code>进行推理，而不会因为共享状态导致竞争条件</li><li><strong>可重现性</strong>：相同的输入总是产生相同的输出，不受历史状态影响</li><li><strong>灵活性</strong>：可以灵活控制何时重置状态、何时复用状态，适应不同的应用场景</li></ol><h4 id=312-状态管理的责任归属>3.1.2 状态管理的责任归属<a hidden class=anchor aria-hidden=true href=#312-状态管理的责任归属>#</a></h4><p>在ORT的设计中，<strong>状态管理是应用层的责任</strong>，而不是推理引擎的责任。这样做的好处是：</p><ul><li><strong>应用层控制</strong>：应用可以根据业务需求决定何时重置状态、如何管理多个流的状态</li><li><strong>内存管理</strong>：应用可以精确控制状态的内存分配和释放时机</li><li><strong>多实例支持</strong>：同一个模型可以同时处理多个独立的音频流，每个流维护自己的状态</li></ul><h4 id=313-与训练框架的差异>3.1.3 与训练框架的差异<a hidden class=anchor aria-hidden=true href=#313-与训练框架的差异>#</a></h4><p>在训练框架（如PyTorch、TensorFlow）中，RNN/LSTM层通常会维护隐状态：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># PyTorch训练时的行为</span>
</span></span><span class=line><span class=cl><span class=n>lstm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LSTM</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>hidden_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>output</span><span class=p>,</span> <span class=p>(</span><span class=n>hidden</span><span class=p>,</span> <span class=n>cell</span><span class=p>)</span> <span class=o>=</span> <span class=n>lstm</span><span class=p>(</span><span class=nb>input</span><span class=p>,</span> <span class=p>(</span><span class=n>hidden</span><span class=p>,</span> <span class=n>cell</span><span class=p>))</span>  <span class=c1># 状态在层内部管理</span></span></span></code></pre></td></tr></table></div></div><p>但在ONNX导出和ORT推理时，隐状态被<strong>显式化</strong>为模型的输入和输出：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>// ONNX模型结构
</span></span></span><span class=line><span class=cl><span class=c1>// 输入: [audio_features, hidden_state, cell_state]  // 显式输入
</span></span></span><span class=line><span class=cl><span class=c1>// 输出: [denoised_features, new_hidden_state, new_cell_state]  // 显式输出
</span></span></span></code></pre></td></tr></table></div></div><p>这种显式化的设计使得：</p><ul><li>状态在模型外部可见和可控</li><li>可以跨框架、跨平台保持一致的行为</li><li>便于调试和优化</li></ul><h4 id=314-实际影响>3.1.4 实际影响<a hidden class=anchor aria-hidden=true href=#314-实际影响>#</a></h4><p>对于语音降噪等时序应用，ORT不保存隐状态意味着：</p><ol><li><strong>必须手动传递状态</strong>：每次推理时，需要将上一次的输出状态作为下一次的输入</li><li><strong>状态持久化由应用负责</strong>：如果需要保存状态（如断点续传），需要应用层实现</li><li><strong>多流处理需要独立状态</strong>：处理多个音频流时，需要为每个流维护独立的状态变量</li></ol><p>这种设计虽然增加了应用层的复杂度，但提供了更大的灵活性和控制力，特别适合生产环境中的复杂场景。</p><h3 id=32-实战使用ort进行rnnoise降噪推理>3.2 实战使用ORT进行Rnnoise降噪推理<a hidden class=anchor aria-hidden=true href=#32-实战使用ort进行rnnoise降噪推理>#</a></h3><p>RNNoise是一个基于深度学习的实时语音降噪模型，使用了三个GRU层（VAD GRU、Noise GRU、Denoise GRU）进行时序建模。在使用ORT进行推理时，需要特别注意这三个GRU层的隐状态管理。</p><h4 id=321-转换成onnx模型时导出gru隐状态输入输出端口>3.2.1 转换成ONNX模型时导出GRU隐状态输入输出端口<a hidden class=anchor aria-hidden=true href=#321-转换成onnx模型时导出gru隐状态输入输出端口>#</a></h4><p>RNNoise的Keras训练模型通常只接受特征输入，GRU的隐状态在内部管理。但在导出ONNX模型用于ORT推理时，需要将隐状态显式化为模型的输入和输出端口，这样才能在应用层控制状态传递。</p><p><strong>关键步骤：</strong></p><ol><li><strong>重建模型结构</strong>：创建一个新的推理模型，为每个GRU层添加<code>initial_state</code>输入和<code>return_state=True</code>输出</li><li><strong>复制权重</strong>：从训练模型复制所有层的权重到新模型</li><li><strong>定义输入输出</strong>：新模型有4个输入（features + 3个GRU状态）和5个输出（denoise_output + vad_output + 3个GRU状态）</li></ol><p>下图中，左侧为没有导出隐状态的onnx模型可视化图，可以看到gru的隐状态每次都是被重置的；右侧为导出了隐状态的onnx模型可视化图，可以看到gru节点对应了一个gru state输入端口和一个gru state的输出端口。</p><p><img alt=rnnoise-onnx-导出隐状态 loading=lazy src=/images/2025-11-03/rnnoise-onnx-%E5%AF%BC%E5%87%BA%E9%9A%90%E7%8A%B6%E6%80%81.jpg></p><p>以下是完整的转换代码：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>keras.backend</span> <span class=k>as</span> <span class=nn>K</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.constraints</span> <span class=kn>import</span> <span class=n>Constraint</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.layers</span> <span class=kn>import</span> <span class=n>Input</span><span class=p>,</span> <span class=n>Dense</span><span class=p>,</span> <span class=n>GRU</span><span class=p>,</span> <span class=n>concatenate</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>keras.models</span> <span class=kn>import</span> <span class=n>Model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>my_crossentropy</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>K</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>binary_crossentropy</span><span class=p>(</span><span class=n>y_pred</span><span class=p>,</span> <span class=n>y_true</span><span class=p>),</span> <span class=n>axis</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mymask</span><span class=p>(</span><span class=n>y_true</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>K</span><span class=o>.</span><span class=n>minimum</span><span class=p>(</span><span class=n>y_true</span> <span class=o>+</span> <span class=mf>1.0</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>msse</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>K</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>mymask</span><span class=p>(</span><span class=n>y_true</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>K</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>y_pred</span><span class=p>)</span> <span class=o>-</span> <span class=n>K</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>y_true</span><span class=p>)),</span> <span class=n>axis</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mycost</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>K</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>mymask</span><span class=p>(</span><span class=n>y_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>*</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=mi>10</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>K</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>K</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>y_pred</span><span class=p>)</span> <span class=o>-</span> <span class=n>K</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>y_true</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>            <span class=o>+</span> <span class=n>K</span><span class=o>.</span><span class=n>square</span><span class=p>(</span><span class=n>K</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>y_pred</span><span class=p>)</span> <span class=o>-</span> <span class=n>K</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>y_true</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=o>+</span> <span class=mf>0.01</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>binary_crossentropy</span><span class=p>(</span><span class=n>y_pred</span><span class=p>,</span> <span class=n>y_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>axis</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>my_accuracy</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>K</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>abs</span><span class=p>(</span><span class=n>y_true</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>)</span> <span class=o>*</span> <span class=n>K</span><span class=o>.</span><span class=n>equal</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>K</span><span class=o>.</span><span class=n>round</span><span class=p>(</span><span class=n>y_pred</span><span class=p>)),</span> <span class=n>axis</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>WeightClip</span><span class=p>(</span><span class=n>Constraint</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Accept **kwargs to be compatible with Keras deserialization that may pass &#39;name&#39; etc.</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>c</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>  <span class=c1># kwargs may include &#39;name&#39;</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>c</span> <span class=o>=</span> <span class=n>c</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__call__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>p</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>K</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>p</span><span class=p>,</span> <span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>c</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>c</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_config</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=p>,</span> <span class=s1>&#39;c&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>c</span><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>CUSTOM_OBJECTS</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;my_crossentropy&#39;</span><span class=p>:</span> <span class=n>my_crossentropy</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;mymask&#39;</span><span class=p>:</span> <span class=n>mymask</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;msse&#39;</span><span class=p>:</span> <span class=n>msse</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;mycost&#39;</span><span class=p>:</span> <span class=n>mycost</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;my_accuracy&#39;</span><span class=p>:</span> <span class=n>my_accuracy</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;WeightClip&#39;</span><span class=p>:</span> <span class=n>WeightClip</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>rebuild_model_with_states</span><span class=p>(</span><span class=n>training_model</span><span class=p>:</span> <span class=n>Model</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Model</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    自动重建模型，添加GRU隐状态输入/输出端口。
</span></span></span><span class=line><span class=cl><span class=s2>    如果模型已经有GRU状态端口，直接返回原模型。
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 检查是否已有GRU状态端口</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>training_model</span><span class=o>.</span><span class=n>inputs</span><span class=p>)</span> <span class=o>==</span> <span class=mi>4</span> <span class=ow>and</span> <span class=nb>len</span><span class=p>(</span><span class=n>training_model</span><span class=o>.</span><span class=n>outputs</span><span class=p>)</span> <span class=o>==</span> <span class=mi>5</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  Model already has GRU state ports, skipping rebuild&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>training_model</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  Rebuilding model with GRU state inputs/outputs...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 新的推理输入（带状态）</span>
</span></span><span class=line><span class=cl>    <span class=n>features_in</span> <span class=o>=</span> <span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=mi>42</span><span class=p>),</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;features&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_state_in</span> <span class=o>=</span> <span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>24</span><span class=p>,),</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;vad_gru_state&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>noise_state_in</span> <span class=o>=</span> <span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>48</span><span class=p>,),</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;noise_gru_state&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_state_in</span> <span class=o>=</span> <span class=n>Input</span><span class=p>(</span><span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>96</span><span class=p>,),</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;denoise_gru_state&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 复制训练模型的层配置并加载权重</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1) input_dense</span>
</span></span><span class=line><span class=cl>    <span class=n>input_dense_src</span> <span class=o>=</span> <span class=n>training_model</span><span class=o>.</span><span class=n>get_layer</span><span class=p>(</span><span class=s1>&#39;input_dense&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>input_dense</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=mi>24</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;input_dense_export&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>kernel_constraint</span><span class=o>=</span><span class=n>input_dense_src</span><span class=o>.</span><span class=n>kernel_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>bias_constraint</span><span class=o>=</span><span class=n>input_dense_src</span><span class=o>.</span><span class=n>bias_constraint</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tmp_export</span> <span class=o>=</span> <span class=n>input_dense</span><span class=p>(</span><span class=n>features_in</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>input_dense</span><span class=o>.</span><span class=n>set_weights</span><span class=p>(</span><span class=n>input_dense_src</span><span class=o>.</span><span class=n>get_weights</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2) vad_gru (return_sequences+return_state)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_gru_src</span> <span class=o>=</span> <span class=n>training_model</span><span class=o>.</span><span class=n>get_layer</span><span class=p>(</span><span class=s1>&#39;vad_gru&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_gru_exp</span> <span class=o>=</span> <span class=n>GRU</span><span class=p>(</span><span class=mi>24</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>,</span> <span class=n>recurrent_activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>return_sequences</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>return_state</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;vad_gru_export&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>kernel_regularizer</span><span class=o>=</span><span class=n>vad_gru_src</span><span class=o>.</span><span class=n>kernel_regularizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>recurrent_regularizer</span><span class=o>=</span><span class=n>vad_gru_src</span><span class=o>.</span><span class=n>recurrent_regularizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>kernel_constraint</span><span class=o>=</span><span class=n>vad_gru_src</span><span class=o>.</span><span class=n>kernel_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>recurrent_constraint</span><span class=o>=</span><span class=n>vad_gru_src</span><span class=o>.</span><span class=n>recurrent_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                      <span class=n>bias_constraint</span><span class=o>=</span><span class=n>vad_gru_src</span><span class=o>.</span><span class=n>bias_constraint</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_seq</span><span class=p>,</span> <span class=n>vad_state_out</span> <span class=o>=</span> <span class=n>vad_gru_exp</span><span class=p>(</span><span class=n>tmp_export</span><span class=p>,</span> <span class=n>initial_state</span><span class=o>=</span><span class=n>vad_state_in</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_gru_exp</span><span class=o>.</span><span class=n>set_weights</span><span class=p>(</span><span class=n>vad_gru_src</span><span class=o>.</span><span class=n>get_weights</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3) vad_output</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_output_src</span> <span class=o>=</span> <span class=n>training_model</span><span class=o>.</span><span class=n>get_layer</span><span class=p>(</span><span class=s1>&#39;vad_output&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_output_exp_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;vad_output_export&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                 <span class=n>kernel_constraint</span><span class=o>=</span><span class=n>vad_output_src</span><span class=o>.</span><span class=n>kernel_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                 <span class=n>bias_constraint</span><span class=o>=</span><span class=n>vad_output_src</span><span class=o>.</span><span class=n>bias_constraint</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_output_exp</span> <span class=o>=</span> <span class=n>vad_output_exp_layer</span><span class=p>(</span><span class=n>vad_seq</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>vad_output_exp_layer</span><span class=o>.</span><span class=n>set_weights</span><span class=p>(</span><span class=n>vad_output_src</span><span class=o>.</span><span class=n>get_weights</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 4) noise_gru 输入：concat([tmp_export, vad_seq, features_in])</span>
</span></span><span class=line><span class=cl>    <span class=n>noise_in</span> <span class=o>=</span> <span class=n>concatenate</span><span class=p>([</span><span class=n>tmp_export</span><span class=p>,</span> <span class=n>vad_seq</span><span class=p>,</span> <span class=n>features_in</span><span class=p>],</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;noise_concat_export&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>noise_gru_src</span> <span class=o>=</span> <span class=n>training_model</span><span class=o>.</span><span class=n>get_layer</span><span class=p>(</span><span class=s1>&#39;noise_gru&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>noise_gru_exp</span> <span class=o>=</span> <span class=n>GRU</span><span class=p>(</span><span class=mi>48</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>,</span> <span class=n>recurrent_activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>return_sequences</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>return_state</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;noise_gru_export&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>kernel_regularizer</span><span class=o>=</span><span class=n>noise_gru_src</span><span class=o>.</span><span class=n>kernel_regularizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>recurrent_regularizer</span><span class=o>=</span><span class=n>noise_gru_src</span><span class=o>.</span><span class=n>recurrent_regularizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>kernel_constraint</span><span class=o>=</span><span class=n>noise_gru_src</span><span class=o>.</span><span class=n>kernel_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>recurrent_constraint</span><span class=o>=</span><span class=n>noise_gru_src</span><span class=o>.</span><span class=n>recurrent_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>bias_constraint</span><span class=o>=</span><span class=n>noise_gru_src</span><span class=o>.</span><span class=n>bias_constraint</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>noise_seq</span><span class=p>,</span> <span class=n>noise_state_out</span> <span class=o>=</span> <span class=n>noise_gru_exp</span><span class=p>(</span><span class=n>noise_in</span><span class=p>,</span> <span class=n>initial_state</span><span class=o>=</span><span class=n>noise_state_in</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>noise_gru_exp</span><span class=o>.</span><span class=n>set_weights</span><span class=p>(</span><span class=n>noise_gru_src</span><span class=o>.</span><span class=n>get_weights</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 5) denoise_gru 输入：concat([vad_seq, noise_seq, features_in])</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_in</span> <span class=o>=</span> <span class=n>concatenate</span><span class=p>([</span><span class=n>vad_seq</span><span class=p>,</span> <span class=n>noise_seq</span><span class=p>,</span> <span class=n>features_in</span><span class=p>],</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;denoise_concat_export&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_gru_src</span> <span class=o>=</span> <span class=n>training_model</span><span class=o>.</span><span class=n>get_layer</span><span class=p>(</span><span class=s1>&#39;denoise_gru&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_gru_exp</span> <span class=o>=</span> <span class=n>GRU</span><span class=p>(</span><span class=mi>96</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;tanh&#39;</span><span class=p>,</span> <span class=n>recurrent_activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>return_sequences</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>return_state</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;denoise_gru_export&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>kernel_regularizer</span><span class=o>=</span><span class=n>denoise_gru_src</span><span class=o>.</span><span class=n>kernel_regularizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>recurrent_regularizer</span><span class=o>=</span><span class=n>denoise_gru_src</span><span class=o>.</span><span class=n>recurrent_regularizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>kernel_constraint</span><span class=o>=</span><span class=n>denoise_gru_src</span><span class=o>.</span><span class=n>kernel_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>recurrent_constraint</span><span class=o>=</span><span class=n>denoise_gru_src</span><span class=o>.</span><span class=n>recurrent_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                          <span class=n>bias_constraint</span><span class=o>=</span><span class=n>denoise_gru_src</span><span class=o>.</span><span class=n>bias_constraint</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_seq</span><span class=p>,</span> <span class=n>denoise_state_out</span> <span class=o>=</span> <span class=n>denoise_gru_exp</span><span class=p>(</span><span class=n>denoise_in</span><span class=p>,</span> <span class=n>initial_state</span><span class=o>=</span><span class=n>denoise_state_in</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_gru_exp</span><span class=o>.</span><span class=n>set_weights</span><span class=p>(</span><span class=n>denoise_gru_src</span><span class=o>.</span><span class=n>get_weights</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 6) denoise_output</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_output_src</span> <span class=o>=</span> <span class=n>training_model</span><span class=o>.</span><span class=n>get_layer</span><span class=p>(</span><span class=s1>&#39;denoise_output&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_output_exp_layer</span> <span class=o>=</span> <span class=n>Dense</span><span class=p>(</span><span class=mi>22</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;sigmoid&#39;</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;denoise_output_export&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                     <span class=n>kernel_constraint</span><span class=o>=</span><span class=n>denoise_output_src</span><span class=o>.</span><span class=n>kernel_constraint</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                     <span class=n>bias_constraint</span><span class=o>=</span><span class=n>denoise_output_src</span><span class=o>.</span><span class=n>bias_constraint</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_output_exp</span> <span class=o>=</span> <span class=n>denoise_output_exp_layer</span><span class=p>(</span><span class=n>denoise_seq</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>denoise_output_exp_layer</span><span class=o>.</span><span class=n>set_weights</span><span class=p>(</span><span class=n>denoise_output_src</span><span class=o>.</span><span class=n>get_weights</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>export_model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span><span class=o>=</span><span class=p>[</span><span class=n>features_in</span><span class=p>,</span> <span class=n>vad_state_in</span><span class=p>,</span> <span class=n>noise_state_in</span><span class=p>,</span> <span class=n>denoise_state_in</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span><span class=o>=</span><span class=p>[</span><span class=n>denoise_output_exp</span><span class=p>,</span> <span class=n>vad_output_exp</span><span class=p>,</span> <span class=n>vad_state_out</span><span class=p>,</span> <span class=n>noise_state_out</span><span class=p>,</span> <span class=n>denoise_state_out</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>name</span><span class=o>=</span><span class=s1>&#39;rnnoise_export_with_states&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  ✓ Model rebuilt successfully with GRU state ports&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>export_model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>convert</span><span class=p>(</span><span class=n>hdf5_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>onnx_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>opset</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>13</span><span class=p>,</span> <span class=n>auto_rebuild</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=kc>False</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>isfile</span><span class=p>(</span><span class=n>hdf5_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>FileNotFoundError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;HDF5 model not found: </span><span class=si>{</span><span class=n>hdf5_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loading Keras model from: </span><span class=si>{</span><span class=n>hdf5_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Load with custom objects registered for deserialization</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>keras</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>hdf5_path</span><span class=p>,</span> <span class=n>custom_objects</span><span class=o>=</span><span class=n>CUSTOM_OBJECTS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Auto-rebuild model with GRU states if needed</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>auto_rebuild</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>=== Auto-Rebuild Mode ===&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  Checking if model needs GRU state ports...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>rebuild_model_with_states</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;  Model ready for conversion with GRU state ports</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Check if the model has GRU state inputs/outputs</span>
</span></span><span class=line><span class=cl>    <span class=n>num_inputs</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>num_outputs</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>outputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Model has </span><span class=si>{</span><span class=n>num_inputs</span><span class=si>}</span><span class=s2> input(s) and </span><span class=si>{</span><span class=n>num_outputs</span><span class=si>}</span><span class=s2> output(s)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Print input information</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>inp</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>inputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Input </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>inp</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>, shape: </span><span class=si>{</span><span class=n>inp</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Print output information</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>out</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>outputs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  Output </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>out</span><span class=o>.</span><span class=n>name</span><span class=si>}</span><span class=s2>, shape: </span><span class=si>{</span><span class=n>out</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># Check if this is a model with GRU states (4 inputs and 5 outputs)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>num_inputs</span> <span class=o>==</span> <span class=mi>4</span> <span class=ow>and</span> <span class=n>num_outputs</span> <span class=o>==</span> <span class=mi>5</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Detected model with GRU state inputs/outputs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Build input signature for model with efficient state management</span>
</span></span><span class=line><span class=cl>        <span class=n>input_specs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>inp</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>inputs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>inp_name</span> <span class=o>=</span> <span class=n>inp</span><span class=o>.</span><span class=n>name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;:&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>inp_shape</span> <span class=o>=</span> <span class=n>inp</span><span class=o>.</span><span class=n>shape</span><span class=o>.</span><span class=n>as_list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=c1># Handle different input shapes</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>inp_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>3</span><span class=p>:</span>  <span class=c1># features: (None, None, 42)</span>
</span></span><span class=line><span class=cl>                <span class=n>spec</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>TensorSpec</span><span class=p>([</span><span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>inp_shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]],</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=n>inp_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>elif</span> <span class=nb>len</span><span class=p>(</span><span class=n>inp_shape</span><span class=p>)</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>  <span class=c1># GRU states: (None, hidden_size)</span>
</span></span><span class=line><span class=cl>                <span class=n>spec</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>TensorSpec</span><span class=p>([</span><span class=kc>None</span><span class=p>,</span> <span class=n>inp_shape</span><span class=p>[</span><span class=mi>1</span><span class=p>]],</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=n>inp_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># Fallback: use dynamic shape</span>
</span></span><span class=line><span class=cl>                <span class=n>spec</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>TensorSpec</span><span class=p>([</span><span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>inp_shape</span><span class=p>),</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=n>inp_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=n>input_specs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>spec</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Converting to ONNX (opset </span><span class=si>{</span><span class=n>opset</span><span class=si>}</span><span class=s2>) with GRU state inputs/outputs...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Convert with all input signatures</span>
</span></span><span class=line><span class=cl>        <span class=n>tf2onnx</span><span class=o>.</span><span class=n>convert</span><span class=o>.</span><span class=n>from_keras</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_signature</span><span class=o>=</span><span class=n>input_specs</span><span class=p>,</span> <span class=n>output_path</span><span class=o>=</span><span class=n>onnx_path</span><span class=p>,</span> <span class=n>opset</span><span class=o>=</span><span class=n>opset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>num_inputs</span> <span class=o>==</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Detected standard model without GRU state ports&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Use a dynamic input signature (None, None, 42) to preserve time dimension flexibility</span>
</span></span><span class=line><span class=cl>        <span class=n>input_name</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>inputs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;:&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>spec</span> <span class=o>=</span> <span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>TensorSpec</span><span class=p>([</span><span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=mi>42</span><span class=p>],</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=n>input_name</span><span class=p>),)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Converting to ONNX (opset </span><span class=si>{</span><span class=n>opset</span><span class=si>}</span><span class=s2>)...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Convert directly from the Keras model</span>
</span></span><span class=line><span class=cl>        <span class=n>tf2onnx</span><span class=o>.</span><span class=n>convert</span><span class=o>.</span><span class=n>from_keras</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_signature</span><span class=o>=</span><span class=n>spec</span><span class=p>,</span> <span class=n>output_path</span><span class=o>=</span><span class=n>onnx_path</span><span class=p>,</span> <span class=n>opset</span><span class=o>=</span><span class=n>opset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># Generic conversion for models with multiple inputs but unknown structure</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Converting to ONNX (opset </span><span class=si>{</span><span class=n>opset</span><span class=si>}</span><span class=s2>) with </span><span class=si>{</span><span class=n>num_inputs</span><span class=si>}</span><span class=s2> inputs...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>input_specs</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>inp</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>inputs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>inp_name</span> <span class=o>=</span> <span class=n>inp</span><span class=o>.</span><span class=n>name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;:&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>inp_shape</span> <span class=o>=</span> <span class=n>inp</span><span class=o>.</span><span class=n>shape</span><span class=o>.</span><span class=n>as_list</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=c1># Use dynamic shapes for flexibility</span>
</span></span><span class=line><span class=cl>            <span class=n>spec</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>TensorSpec</span><span class=p>([</span><span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=nb>len</span><span class=p>(</span><span class=n>inp_shape</span><span class=p>),</span> <span class=n>tf</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=n>inp_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>input_specs</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>spec</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tf2onnx</span><span class=o>.</span><span class=n>convert</span><span class=o>.</span><span class=n>from_keras</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>input_signature</span><span class=o>=</span><span class=n>input_specs</span><span class=p>,</span> <span class=n>output_path</span><span class=o>=</span><span class=n>onnx_path</span><span class=p>,</span> <span class=n>opset</span><span class=o>=</span><span class=n>opset</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Saved ONNX model to: </span><span class=si>{</span><span class=n>onnx_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s1>&#39;Convert Keras HDF5 model to ONNX for RNNoise.&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--input&#39;</span><span class=p>,</span> <span class=s1>&#39;-i&#39;</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;Path to Keras HDF5 model file&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--output&#39;</span><span class=p>,</span> <span class=s1>&#39;-o&#39;</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;Path to output ONNX file&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--opset&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>13</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s1>&#39;ONNX opset version (default: 13)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--auto-rebuild&#39;</span><span class=p>,</span> <span class=n>action</span><span class=o>=</span><span class=s1>&#39;store_true&#39;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                        <span class=n>help</span><span class=o>=</span><span class=s1>&#39;Automatically rebuild model with GRU state ports if missing&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>input_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>output_path</span> <span class=o>=</span> <span class=n>args</span><span class=o>.</span><span class=n>output</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>output_path</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>base</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>splitext</span><span class=p>(</span><span class=n>input_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output_path</span> <span class=o>=</span> <span class=n>base</span> <span class=o>+</span> <span class=s1>&#39;.onnx&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>output_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>abspath</span><span class=p>(</span><span class=n>output_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>output_path</span><span class=p>),</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>convert</span><span class=p>(</span><span class=n>input_path</span><span class=p>,</span> <span class=n>output_path</span><span class=p>,</span> <span class=n>opset</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>opset</span><span class=p>,</span> <span class=n>auto_rebuild</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>auto_rebuild</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span></span></span></code></pre></td></tr></table></div></div><h4 id=322-推理时对隐状态进行管理>3.2.2 推理时对隐状态进行管理<a hidden class=anchor aria-hidden=true href=#322-推理时对隐状态进行管理>#</a></h4><p>前面导出onnx模型时，已经为每个GRU节点导出了隐状态的输入和输出端口，因此在每一次帧的时候，只需要将上一次推理保存的隐状态信息输入到对应的隐状态输入端口，同时在推理后对GRU节点的隐状态输出端口进行保存，就可以实现流式推理GRU保留历史信息了。</p><p>以下是部分核心函数实现，只需要将其嵌入到原rnnoise降噪代码中就可以实现ort推理了。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span><span class=lnt>176
</span><span class=lnt>177
</span><span class=lnt>178
</span><span class=lnt>179
</span><span class=lnt>180
</span><span class=lnt>181
</span><span class=lnt>182
</span><span class=lnt>183
</span><span class=lnt>184
</span><span class=lnt>185
</span><span class=lnt>186
</span><span class=lnt>187
</span><span class=lnt>188
</span><span class=lnt>189
</span><span class=lnt>190
</span><span class=lnt>191
</span><span class=lnt>192
</span><span class=lnt>193
</span><span class=lnt>194
</span><span class=lnt>195
</span><span class=lnt>196
</span><span class=lnt>197
</span><span class=lnt>198
</span><span class=lnt>199
</span><span class=lnt>200
</span><span class=lnt>201
</span><span class=lnt>202
</span><span class=lnt>203
</span><span class=lnt>204
</span><span class=lnt>205
</span><span class=lnt>206
</span><span class=lnt>207
</span><span class=lnt>208
</span><span class=lnt>209
</span><span class=lnt>210
</span><span class=lnt>211
</span><span class=lnt>212
</span><span class=lnt>213
</span><span class=lnt>214
</span><span class=lnt>215
</span><span class=lnt>216
</span><span class=lnt>217
</span><span class=lnt>218
</span><span class=lnt>219
</span><span class=lnt>220
</span><span class=lnt>221
</span><span class=lnt>222
</span><span class=lnt>223
</span><span class=lnt>224
</span><span class=lnt>225
</span><span class=lnt>226
</span><span class=lnt>227
</span><span class=lnt>228
</span><span class=lnt>229
</span><span class=lnt>230
</span><span class=lnt>231
</span><span class=lnt>232
</span><span class=lnt>233
</span><span class=lnt>234
</span><span class=lnt>235
</span><span class=lnt>236
</span><span class=lnt>237
</span><span class=lnt>238
</span><span class=lnt>239
</span><span class=lnt>240
</span><span class=lnt>241
</span><span class=lnt>242
</span><span class=lnt>243
</span><span class=lnt>244
</span><span class=lnt>245
</span><span class=lnt>246
</span><span class=lnt>247
</span><span class=lnt>248
</span><span class=lnt>249
</span><span class=lnt>250
</span><span class=lnt>251
</span><span class=lnt>252
</span><span class=lnt>253
</span><span class=lnt>254
</span><span class=lnt>255
</span><span class=lnt>256
</span><span class=lnt>257
</span><span class=lnt>258
</span><span class=lnt>259
</span><span class=lnt>260
</span><span class=lnt>261
</span><span class=lnt>262
</span><span class=lnt>263
</span><span class=lnt>264
</span><span class=lnt>265
</span><span class=lnt>266
</span><span class=lnt>267
</span><span class=lnt>268
</span><span class=lnt>269
</span><span class=lnt>270
</span><span class=lnt>271
</span><span class=lnt>272
</span><span class=lnt>273
</span><span class=lnt>274
</span><span class=lnt>275
</span><span class=lnt>276
</span><span class=lnt>277
</span><span class=lnt>278
</span><span class=lnt>279
</span><span class=lnt>280
</span><span class=lnt>281
</span><span class=lnt>282
</span><span class=lnt>283
</span><span class=lnt>284
</span><span class=lnt>285
</span><span class=lnt>286
</span><span class=lnt>287
</span><span class=lnt>288
</span><span class=lnt>289
</span><span class=lnt>290
</span><span class=lnt>291
</span><span class=lnt>292
</span><span class=lnt>293
</span><span class=lnt>294
</span><span class=lnt>295
</span><span class=lnt>296
</span><span class=lnt>297
</span><span class=lnt>298
</span><span class=lnt>299
</span><span class=lnt>300
</span><span class=lnt>301
</span><span class=lnt>302
</span><span class=lnt>303
</span><span class=lnt>304
</span><span class=lnt>305
</span><span class=lnt>306
</span><span class=lnt>307
</span><span class=lnt>308
</span><span class=lnt>309
</span><span class=lnt>310
</span><span class=lnt>311
</span><span class=lnt>312
</span><span class=lnt>313
</span><span class=lnt>314
</span><span class=lnt>315
</span><span class=lnt>316
</span><span class=lnt>317
</span><span class=lnt>318
</span><span class=lnt>319
</span><span class=lnt>320
</span><span class=lnt>321
</span><span class=lnt>322
</span><span class=lnt>323
</span><span class=lnt>324
</span><span class=lnt>325
</span><span class=lnt>326
</span><span class=lnt>327
</span><span class=lnt>328
</span><span class=lnt>329
</span><span class=lnt>330
</span><span class=lnt>331
</span><span class=lnt>332
</span><span class=lnt>333
</span><span class=lnt>334
</span><span class=lnt>335
</span><span class=lnt>336
</span><span class=lnt>337
</span><span class=lnt>338
</span><span class=lnt>339
</span><span class=lnt>340
</span><span class=lnt>341
</span><span class=lnt>342
</span><span class=lnt>343
</span><span class=lnt>344
</span><span class=lnt>345
</span><span class=lnt>346
</span><span class=lnt>347
</span><span class=lnt>348
</span><span class=lnt>349
</span><span class=lnt>350
</span><span class=lnt>351
</span><span class=lnt>352
</span><span class=lnt>353
</span><span class=lnt>354
</span><span class=lnt>355
</span><span class=lnt>356
</span><span class=lnt>357
</span><span class=lnt>358
</span><span class=lnt>359
</span><span class=lnt>360
</span><span class=lnt>361
</span><span class=lnt>362
</span><span class=lnt>363
</span><span class=lnt>364
</span><span class=lnt>365
</span><span class=lnt>366
</span><span class=lnt>367
</span><span class=lnt>368
</span><span class=lnt>369
</span><span class=lnt>370
</span><span class=lnt>371
</span><span class=lnt>372
</span><span class=lnt>373
</span><span class=lnt>374
</span><span class=lnt>375
</span><span class=lnt>376
</span><span class=lnt>377
</span><span class=lnt>378
</span><span class=lnt>379
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c data-lang=c><span class=line><span class=cl><span class=c1>// Initialize ONNX model
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=nf>initialize_onnx_model</span><span class=p>(</span><span class=n>RNNoiseContext</span><span class=o>*</span> <span class=n>ctx</span><span class=p>,</span> <span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>model_path</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Get ONNX Runtime API
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=n>OrtApiBase</span><span class=o>*</span> <span class=n>api_base</span> <span class=o>=</span> <span class=nf>OrtGetApiBase</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>api_base</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting ONNX Runtime API base</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span> <span class=o>=</span> <span class=n>api_base</span><span class=o>-&gt;</span><span class=nf>GetApi</span><span class=p>(</span><span class=n>ORT_API_VERSION</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting ONNX Runtime API</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Initialize ONNX Runtime environment
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>OrtStatus</span><span class=o>*</span> <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateEnv</span><span class=p>(</span><span class=n>ORT_LOGGING_LEVEL_WARNING</span><span class=p>,</span> <span class=s>&#34;RNNoiseONNX&#34;</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>env</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating ONNX Runtime environment</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Create session options
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateSessionOptions</span><span class=p>(</span><span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session_options</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating session options</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Set session options
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SetIntraOpNumThreads</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session_options</span><span class=p>,</span> <span class=mi>1</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error setting intra-op threads</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SetSessionGraphOptimizationLevel</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session_options</span><span class=p>,</span> <span class=n>ORT_ENABLE_EXTENDED</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error setting optimization level</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Create session
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateSession</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>env</span><span class=p>,</span> <span class=n>model_path</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session_options</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating ONNX session</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Get allocator
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>GetAllocatorWithDefaultOptions</span><span class=p>(</span><span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting allocator</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Get input/output names
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>size_t</span> <span class=n>num_input_nodes</span><span class=p>,</span> <span class=n>num_output_nodes</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetInputCount</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>num_input_nodes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting input count</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputCount</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>num_output_nodes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting output count</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;ONNX Model Info:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Input nodes: %zu</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>num_input_nodes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Output nodes: %zu</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>num_output_nodes</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Detect model type: 4 inputs + 5 outputs = model with GRU states
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>has_gru_states</span> <span class=o>=</span> <span class=p>(</span><span class=n>num_input_nodes</span> <span class=o>==</span> <span class=mi>4</span> <span class=o>&amp;&amp;</span> <span class=n>num_output_nodes</span> <span class=o>==</span> <span class=mi>5</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>has_gru_states</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Model type: WITH GRU state inputs/outputs</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1>// Get all input names
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetInputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting features input name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetInputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_vad_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting VAD state input name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetInputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_noise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting noise state input name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetInputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_denoise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting denoise state input name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1>// Get all output names
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting denoise output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting VAD output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting VAD state output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_noise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting noise state output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting denoise state output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Inputs:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [0] %s (features)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [1] %s (VAD GRU state)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_vad_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [2] %s (noise GRU state)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_noise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [3] %s (denoise GRU state)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_denoise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Outputs:</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [0] %s (denoise)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [1] %s (VAD)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [2] %s (VAD GRU state)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [3] %s (noise GRU state)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_noise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;    [4] %s (denoise GRU state)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span> <span class=k>else</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Model type: Standard (without GRU state ports)</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1>// Get input name (standard model)
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetInputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting input name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1>// Get output names (standard model)
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting denoise output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>SessionGetOutputName</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>allocator</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting VAD output name</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Input: %s</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Output denoise: %s</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;  Output VAD: %s</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Allocate buffers
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_buffer</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>FRAME_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_buffer</span> <span class=o>=</span> <span class=p>(</span><span class=kt>float</span><span class=o>*</span><span class=p>)</span><span class=nf>malloc</span><span class=p>(</span><span class=n>FRAME_SIZE</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_buffer</span> <span class=o>||</span> <span class=o>!</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_buffer</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error: Memory allocation failed</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Initialize RNNoise state for feature extraction
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_state</span> <span class=o>=</span> <span class=nf>rnnoise_create</span><span class=p>(</span><span class=nb>NULL</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=o>!</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_state</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error: Failed to create RNNoise state</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nf>rnnoise_init</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_state</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Initialize biquad filter memory
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>mem_hp_x</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=mf>0.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>mem_hp_x</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>=</span> <span class=mf>0.0f</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Initialize processing buffers
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>X</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>X</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>P</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>P</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>Ex</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>Ex</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>Ep</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>Ep</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>Exp</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>Exp</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>lastg</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>lastg</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>synthesis_mem</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>synthesis_mem</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Initialize frame count
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>frame_count</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Initialize GRU states if model supports it
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>initialize_gru_states</span><span class=p>(</span><span class=n>ctx</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=nf>printf</span><span class=p>(</span><span class=s>&#34;ONNX model loaded successfully: %s</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>,</span> <span class=n>model_path</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// Initialize GRU states
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>void</span> <span class=nf>initialize_gru_states</span><span class=p>(</span><span class=n>RNNoiseContext</span><span class=o>*</span> <span class=n>ctx</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>vad_gru_state</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>vad_gru_state</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>noise_gru_state</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>noise_gru_state</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memset</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_gru_state</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=k>sizeof</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_gru_state</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>gru_states_initialized</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1>// ONNX inference with external state management
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=nf>onnx_inference_with_states</span><span class=p>(</span><span class=n>RNNoiseContext</span><span class=o>*</span> <span class=n>ctx</span><span class=p>,</span> <span class=k>const</span> <span class=kt>float</span><span class=o>*</span> <span class=n>features</span><span class=p>,</span> <span class=kt>float</span><span class=o>*</span> <span class=n>gains</span><span class=p>,</span> <span class=kt>float</span><span class=o>*</span> <span class=n>vad</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Prepare separate input tensors for features and GRU states
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>float</span> <span class=n>features_data</span><span class=p>[</span><span class=mi>42</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>vad_state_data</span><span class=p>[</span><span class=mi>24</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>noise_state_data</span><span class=p>[</span><span class=mi>48</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span> <span class=n>denoise_state_data</span><span class=p>[</span><span class=mi>96</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Copy features
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>features_data</span><span class=p>,</span> <span class=n>features</span><span class=p>,</span> <span class=mi>42</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Copy GRU states (use saved states for next frame)
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>vad_state_data</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>vad_gru_state</span><span class=p>,</span> <span class=mi>24</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>noise_state_data</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>noise_gru_state</span><span class=p>,</span> <span class=mi>48</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>denoise_state_data</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_gru_state</span><span class=p>,</span> <span class=mi>96</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Create input tensors
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>int64_t</span> <span class=n>features_shape</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>42</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int64_t</span> <span class=n>vad_state_shape</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>1</span><span class=p>,</span> <span class=mi>24</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int64_t</span> <span class=n>noise_state_shape</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>1</span><span class=p>,</span> <span class=mi>48</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    <span class=k>const</span> <span class=kt>int64_t</span> <span class=n>denoise_state_shape</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=mi>1</span><span class=p>,</span> <span class=mi>96</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>OrtMemoryInfo</span><span class=o>*</span> <span class=n>memory_info</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>OrtStatus</span><span class=o>*</span> <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateCpuMemoryInfo</span><span class=p>(</span><span class=n>OrtArenaAllocator</span><span class=p>,</span> <span class=n>OrtMemTypeDefault</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating memory info</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Create input tensors
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>OrtValue</span><span class=o>*</span> <span class=n>features_tensor</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>OrtValue</span><span class=o>*</span> <span class=n>vad_state_tensor</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>OrtValue</span><span class=o>*</span> <span class=n>noise_state_tensor</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=n>OrtValue</span><span class=o>*</span> <span class=n>denoise_state_tensor</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateTensorWithDataAsOrtValue</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>memory_info</span><span class=p>,</span> <span class=n>features_data</span><span class=p>,</span> <span class=mi>42</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>features_shape</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>features_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating features tensor</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateTensorWithDataAsOrtValue</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>memory_info</span><span class=p>,</span> <span class=n>vad_state_data</span><span class=p>,</span> <span class=mi>24</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>vad_state_shape</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>vad_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating VAD state tensor</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>features_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateTensorWithDataAsOrtValue</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>memory_info</span><span class=p>,</span> <span class=n>noise_state_data</span><span class=p>,</span> <span class=mi>48</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>noise_state_shape</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>noise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating noise state tensor</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>features_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>vad_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>CreateTensorWithDataAsOrtValue</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>memory_info</span><span class=p>,</span> <span class=n>denoise_state_data</span><span class=p>,</span> <span class=mi>96</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>denoise_state_shape</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT</span><span class=p>,</span> <span class=o>&amp;</span><span class=n>denoise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error creating denoise state tensor</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>features_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>vad_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>noise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Prepare input names and tensors
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>input_names</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_vad_state</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                                 <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_noise_state</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>input_name_denoise_state</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    <span class=n>OrtValue</span><span class=o>*</span> <span class=n>input_tensors</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=n>features_tensor</span><span class=p>,</span> <span class=n>vad_state_tensor</span><span class=p>,</span> <span class=n>noise_state_tensor</span><span class=p>,</span> <span class=n>denoise_state_tensor</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Prepare output names
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>const</span> <span class=kt>char</span><span class=o>*</span> <span class=n>output_names</span><span class=p>[]</span> <span class=o>=</span> <span class=p>{</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                                  <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_vad_state</span><span class=p>,</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_noise_state</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>                                  <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>output_name_denoise_state</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    <span class=n>OrtValue</span><span class=o>*</span> <span class=n>output_tensors</span><span class=p>[</span><span class=mi>5</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span><span class=nb>NULL</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>};</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Run inference
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>Run</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>session</span><span class=p>,</span> <span class=nb>NULL</span><span class=p>,</span> <span class=n>input_names</span><span class=p>,</span> <span class=p>(</span><span class=k>const</span> <span class=n>OrtValue</span><span class=o>*</span> <span class=k>const</span><span class=o>*</span><span class=p>)</span><span class=n>input_tensors</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                   <span class=n>output_names</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>output_tensors</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error running inference</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>features_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>vad_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>noise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>denoise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=o>-</span><span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Get output data
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kt>float</span><span class=o>*</span> <span class=n>denoise_output</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>vad_output</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>updated_vad_state</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>updated_noise_state</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=kt>float</span><span class=o>*</span> <span class=n>updated_denoise_state</span> <span class=o>=</span> <span class=nb>NULL</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>GetTensorMutableData</span><span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=p>(</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>denoise_output</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting denoise output data</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>goto</span> <span class=n>cleanup</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>GetTensorMutableData</span><span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=p>(</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>vad_output</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting VAD output data</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>goto</span> <span class=n>cleanup</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>GetTensorMutableData</span><span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=mi>2</span><span class=p>],</span> <span class=p>(</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>updated_vad_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting updated VAD state data</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>goto</span> <span class=n>cleanup</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>GetTensorMutableData</span><span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=mi>3</span><span class=p>],</span> <span class=p>(</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>updated_noise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting updated noise state data</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>goto</span> <span class=n>cleanup</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=n>status</span> <span class=o>=</span> <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>GetTensorMutableData</span><span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=mi>4</span><span class=p>],</span> <span class=p>(</span><span class=kt>void</span><span class=o>**</span><span class=p>)</span><span class=o>&amp;</span><span class=n>updated_denoise_state</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>status</span> <span class=o>!=</span> <span class=nb>NULL</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nf>fprintf</span><span class=p>(</span><span class=n>stderr</span><span class=p>,</span> <span class=s>&#34;Error getting updated denoise state data</span><span class=se>\n</span><span class=s>&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=k>goto</span> <span class=n>cleanup</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Store results
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>gains</span><span class=p>,</span> <span class=n>denoise_output</span><span class=p>,</span> <span class=n>NB_BANDS</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=o>*</span><span class=n>vad</span> <span class=o>=</span> <span class=n>vad_output</span><span class=p>[</span><span class=mi>0</span><span class=p>];</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1>// Update GRU states with the outputs from the model (for next frame)
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>vad_gru_state</span><span class=p>,</span> <span class=n>updated_vad_state</span><span class=p>,</span> <span class=mi>24</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>noise_gru_state</span><span class=p>,</span> <span class=n>updated_noise_state</span><span class=p>,</span> <span class=mi>48</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=nf>memcpy</span><span class=p>(</span><span class=n>ctx</span><span class=o>-&gt;</span><span class=n>denoise_gru_state</span><span class=p>,</span> <span class=n>updated_denoise_state</span><span class=p>,</span> <span class=mi>96</span> <span class=o>*</span> <span class=k>sizeof</span><span class=p>(</span><span class=kt>float</span><span class=p>));</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>gru_states_initialized</span> <span class=o>=</span> <span class=mi>1</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=nl>cleanup</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Cleanup
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>features_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>vad_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>noise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>denoise_state_tensor</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=mi>5</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=n>i</span><span class=p>])</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseValue</span><span class=p>(</span><span class=n>output_tensors</span><span class=p>[</span><span class=n>i</span><span class=p>]);</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=n>ctx</span><span class=o>-&gt;</span><span class=n>api</span><span class=o>-&gt;</span><span class=nf>ReleaseMemoryInfo</span><span class=p>(</span><span class=n>memory_info</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>0</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></td></tr></table></div></div><h3 id=33-推理性能对比>3.3 推理性能对比<a hidden class=anchor aria-hidden=true href=#33-推理性能对比>#</a></h3><p>可以看到在不需要自己手搓各个算子的C实现，借助ORT就可以实现接近5倍的性能提升，这投入回报比可是不要太高了。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>=== Overall Inference Time Statistics ===
</span></span><span class=line><span class=cl>Total frames processed: 2048
</span></span><span class=line><span class=cl>Frames with inference: 2047
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>ONNX Inference:
</span></span><span class=line><span class=cl>  Total time: 73.568 ms
</span></span><span class=line><span class=cl>  Average per frame: 0.036 ms
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>C Inference:
</span></span><span class=line><span class=cl>  Total time: 349.820 ms
</span></span><span class=line><span class=cl>  Average per frame: 0.171 ms
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Comparison:
</span></span><span class=line><span class=cl>  ONNX / C ratio: 0.21x
</span></span><span class=line><span class=cl>  Speedup: 4.76x (ONNX faster)
</span></span><span class=line><span class=cl>==========================================</span></span></code></pre></td></tr></table></div></div><h2 id=四总结>四、总结<a hidden class=anchor aria-hidden=true href=#四总结>#</a></h2><p>ORT作为跨平台的推理引擎，在语音降噪模型部署中具有显著优势。正确使用ORT需要：</p><ol><li><strong>理解基本概念</strong>：掌握InferenceSession、Execution Provider等核心概念</li><li><strong>遵循推理流程</strong>：按照标准的加载、准备、执行、获取结果流程</li><li><strong>管理隐状态</strong>：对于时序模型，必须正确管理隐状态的传递和更新</li><li><strong>性能优化</strong>：根据场景选择合适的优化选项和执行提供者</li></ol><p>对于实时语音降噪场景，隐状态管理是关键，需要仔细设计状态传递逻辑，确保模型能够正确利用历史信息。</p><p>通过合理使用ORT，可以充分发挥深度学习语音降噪模型的性能，实现高效、稳定的实时推理。</p><p>另外，ORT还有很多高级特性，大家可以自己摸索尝试下。</p><img src=/images/To-Be-Continued.jpeg></div><footer class=post-footer><ul class=post-tags><li><a href=https://lyapple2008.github.io/tags/%E9%9F%B3%E9%A2%91%E7%AE%97%E6%B3%95/>音频算法</a></li><li><a href=https://lyapple2008.github.io/tags/%E8%AF%AD%E9%9F%B3%E9%99%8D%E5%99%AA/>语音降噪</a></li><li><a href=https://lyapple2008.github.io/tags/onnx-runtime/>Onnx Runtime</a></li></ul><nav class=paginav><a class=prev href=https://lyapple2008.github.io/posts/202601/2026-01-25-ios%E9%9F%B3%E9%A2%91%E6%8D%95%E8%8E%B7/><span class=title>« 上一页</span><br><span>iOS音频捕获</span>
</a><a class=next href=https://lyapple2008.github.io/posts/202508/2025-08-11-%E9%9F%B3%E9%A2%91%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0/><span class=title>下一页 »</span><br><span>语音增强算法评估指南</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on x" href="https://x.com/intent/tweet/?text=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86&amp;url=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f&amp;hashtags=%e9%9f%b3%e9%a2%91%e7%ae%97%e6%b3%95%2c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%2cOnnxRuntime"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f&amp;title=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86&amp;summary=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86&amp;source=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f&title=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on whatsapp" href="https://api.whatsapp.com/send?text=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86%20-%20https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on telegram" href="https://telegram.me/share/url?text=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86&amp;url=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 使用ORT进行语音降噪模型推理 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e4%bd%bf%e7%94%a8ORT%e8%bf%9b%e8%a1%8c%e8%af%ad%e9%9f%b3%e9%99%8d%e5%99%aa%e6%a8%a1%e5%9e%8b%e6%8e%a8%e7%90%86&u=https%3a%2f%2flyapple2008.github.io%2fposts%2f202511%2f2025-11-03-%25E4%25BD%25BF%25E7%2594%25A8ort%25E8%25BF%259B%25E8%25A1%258C%25E8%25AF%25AD%25E9%259F%25B3%25E9%2599%258D%25E5%2599%25AA%25E6%258E%25A8%25E7%2590%2586%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><section><h2>Comments</h2><div id=comments-utteranc></div></section><script type=text/javascript>function getCurrentTheme(){return document.documentElement.getAttribute("data-theme")||document.body.classList.contains("dark")?"dark":"light"}function loadUtterances(e=!1){const t=document.getElementById("comments-utteranc");if(t!==null){t.innerHTML="";const n=document.createElement("script");n.setAttribute("id","utteranc"),n.setAttribute("src","https://utteranc.es/client.js"),n.setAttribute("data-repo","lyapple2008/comment"),n.setAttribute("data-category","Announcements"),n.setAttribute("data-mapping","pathname"),n.setAttribute("data-reactions-enabled","1"),n.setAttribute("data-emit-metadata","0"),n.setAttribute("data-theme",e?"github-dark":"github-light"),n.setAttribute("data-issue-term","title"),n.setAttribute("crossorigin","anonymous"),n.setAttribute("async","true"),t.appendChild(n)}}const isDarkMode=getCurrentTheme()==="dark";loadUtterances(isDarkMode);const themeObserver=new MutationObserver(e=>{e.forEach(e=>{if(e.type==="attributes"&&e.attributeName==="class"){const e=getCurrentTheme()==="dark";loadUtterances(e),console.log(`changing theme`)}})});themeObserver.observe(document.body,{attributes:!0,attributeFilter:["class"]})</script></article></main><footer class=footer><span>See this site&rsquo;s source code <a href=https://github.com/lyapple2008/lyapple2008.github.io>here</a>, licensed under GPLv3 ·</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>